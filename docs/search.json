[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IQ",
    "section": "",
    "text": "Introduction to Intelligence\nWARNING: THIS IS A WORK IN PROGRESS AND MAY NOT BE ENTIRELY SCIENTIFICALLY ACCURATE. PLEASE DO NOT QUOTE ME ON THIS STUFF SINCE THIS IS NOTHING MORE THAN A HOBBY\n\n\nDefinitions\n(Phenotypically useful definition) “Intelligence is a very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience.” (Gottfredson 1997)\n(Statistically useful definition) “Intelligence is at the pinnacle of the hierarchical model of cognitive abilities that includes a middle level of group factors, such as the cognitive domains of verbal and spatial abilities and memory, and a third level of specific tests and their associated narrow cognitive skills.” (Plomin and Deary 2015)\n\n\n\n\nGottfredson, Linda S. 1997. “Mainstream Science on Intelligence: An Editorial with 52 Signatories, History, and Bibliography.” Intelligence 24 (1): 13–23. https://doi.org/https://doi.org/10.1016/S0160-2896(97)90011-8.\n\n\nPlomin, R, and I J Deary. 2015. “Genetics and Intelligence Differences: Five Special Findings.” Molecular Psychiatry 20 (1): 98–108. https://doi.org/10.1038/mp.2014.105."
  },
  {
    "objectID": "1tooabstract.html#is-it-appropriate-to-define-intelligence",
    "href": "1tooabstract.html#is-it-appropriate-to-define-intelligence",
    "title": "1  What is intelligence?",
    "section": "1.1 Is it appropriate to define intelligence?",
    "text": "1.1 Is it appropriate to define intelligence?\nRegarding the philosophical nature of precisely defining intelligence, “we have, no doubt, a rough and ready idea of what we mean by ‘intelligence’ and other cognate terms. The objective of scientific enquiry is to advance beyond this primitive, common-sense understanding (what is often termed ‘folk psychology’) to a more securely grounded set of scientific theories, based on empirical evidence and capable of ordering the world in possibly new and illuminating ways. We shall not achieve this goal by insisting on a rigorous, precise definition of terms at the outset. New definitions are the end product of scientific enquiry, not its starting point” (Mackintosh 2011, 2)\nWe ask ourselves, “what is intelligence?” (eg. is it: processing speed; reaction time; working memory; verbal ability; spatial ability; rationality; practical intelligence; emotional intelligence etc;) Imagine a variable that predicts how someone does generally in all of these abilities. What should we call this variable?"
  },
  {
    "objectID": "1tooabstract.html#the-g-factor",
    "href": "1tooabstract.html#the-g-factor",
    "title": "1  What is intelligence?",
    "section": "1.2 The g factor",
    "text": "1.2 The g factor\nThe variable described above is commonly referred to as the “general factor of intelligence” or g factor. The g factor is a statistical construct that represents an individual’s overall intelligence level, and it is considered to be a fundamental concept in the field of psychology.\nThe existence of the g factor has been supported by decades of research across a wide range of intelligence tests and measures. For example, individuals who perform well on one cognitive task, such as verbal ability, tend to perform well on other cognitive tasks, such as spatial ability, indicating a positive correlation between various cognitive abilities.\nMoreover, the g factor has been found to predict a range of important life outcomes, such as academic and job performance, income level, and even health outcomes. Therefore, the g factor is not only a theoretical construct, but it also has practical implications for our understanding of human abilities and potential.\nNobody has ever been able to come up with an assessment for any sort of cognitive ability which does not correlate with the rest of them. The intercorrelations are caused by a general underlying factor which consistently explains half of the variance in a battery of cognitive ability tests (Mackintosh 2011, 45); (Deary 2001, 222); (Deary 1998); (Lubinski 2004, 98)."
  },
  {
    "objectID": "1tooabstract.html#the-chc-model",
    "href": "1tooabstract.html#the-chc-model",
    "title": "1  What is intelligence?",
    "section": "1.3 The CHC model",
    "text": "1.3 The CHC model\nThe Cattell-Horn-Carroll (CHC) theory of intelligence is a prominent model that attempts to explain the structure of cognitive abilities. The theory proposes that intelligence is composed of a hierarchical structure of three strata: the general factor (g factor), broad abilities, and narrow abilities.\n\n\n\nCattell–Horn–Carroll theory of intelligence\n\n\nAt the top of the hierarchy is the g factor, which represents a general factor of intelligence that is common to all cognitive tasks. The broad abilities, located in the middle stratum, are a group of abilities that are less general than the g factor but still encompass a range of related cognitive tasks. Examples of broad abilities include fluid reasoning, crystallized intelligence, processing speed, and working memory. Finally, the narrow abilities, located at the bottom stratum, are specific abilities that are highly specialized and task-specific.\nThe CHC theory supports the existence of the g factor by showing that performance on different cognitive tasks is highly correlated, indicating a common underlying factor that influences performance across tasks. In addition, factor analyses of a wide range of intelligence tests consistently reveal a strong first factor that represents the g factor.\nMoreover, the CHC theory provides a framework for understanding the relationships between the g factor and other cognitive abilities. For example, fluid reasoning is considered a broad ability that is strongly related to the g factor and is involved in abstract thinking and problem-solving. Crystallized intelligence, on the other hand, is a broad ability that represents the application of knowledge and skills acquired through experience and education and is less strongly related to the g factor.\nBecause it has an impressive body of empirical support in the research literature (e.g., developmental, neurocognitive, outcome‐criterion), this model of intelligence is the one that psychologists predominantly use. It is used extensively as the foundation for selecting, organizing, and interpreting tests of intelligence and cognitive abilities. (Alfonso et al. 2005);(Beal 2006);(McGrew et al. 2005);(Schneider et al. 2012) Additionally, this model is the most comprehensive and empirically supported psychometric theory of the structure of cognitive abilities to date. (Flanagan and Dixon 2014)\nCHC is the best model from exploratory factor analysis (J. B. Carroll, B, and Press 1993) and is confirmed by confirmatory factor analysis (Gustafsson 1984); (J. Carroll 2003) (Jewsbury, Bowden, and Duff 2017). Confirmatory factor analysis showed that purposely different IQ batteries (CAB, Hawaii Battery, WAIS, etc) were analyzed, and it turned out that the g factors computed from the respective tests were statistically indistinguishable from one another, despite the fact that the tests tapped into partly different sets of abilities. (Johnson et al. 2004); (Johnson, Nijenhuis, and Bouchard 2008)\n\n\n\n\nAlfonso, V. C., D. P. Flanagan, S. Radwan, D. P. Flanagan, and P. L. Harrison. 2005. “The Impact of the Cattell-Horn-Carroll Theory on Test Development and Interpretation of Cognitive and Academic Abilities.” In Contemporary Intellectual Assessment: Theories, Tests, and Issues, 185–202.\n\n\nBeal, A Lynne. 2006. “Review of Contemporary Intellectual Assessment, Theories, Tests and Issues.”\n\n\nCarroll, J. B., C. J. B, and Cambridge University Press. 1993. Human Cognitive Abilities: A Survey of Factor-Analytic Studies. Human Cognitive Abilities: A Survey of Factor-Analytic Studies, no. 1. Cambridge University Press. https://books.google.com/books?id=jp9dt4\\_0\\_cIC.\n\n\nCarroll, John. 2003. “The Higher-Stratum Structure of Cognitive Abilities: Current Evidence Supports g and about Ten Broad Factors.” In The Scientific Study of General Intelligence: Tribute to Arthur R. Jensen, 5–21. https://doi.org/10.1016/B978-008043793-4/50036-2.\n\n\nDeary, Ian. 1998. “Differences in Mental Abilities.” BMJ (Clinical Research Ed.) 317 (7174): 1701–3. https://doi.org/10.1136/bmj.317.7174.1701.\n\n\n———. 2001. Intelligence: A Very Short Introduction. https://doi.org/10.1093/actrade/9780192893215.001.0001.\n\n\nFlanagan, Dawn P., and Shauna G. Dixon. 2014. “The Cattell-Horn-Carroll Theory of Cognitive Abilities.” In Encyclopedia of Special Education. John Wiley & Sons, Ltd. https://doi.org/https://doi.org/10.1002/9781118660584.ese0431.\n\n\nGustafsson, Jan-Eric. 1984. “A Unifying Model for the Structure of Intellectual Abilities.” Intelligence 8 (3): 179–203. https://doi.org/https://doi.org/10.1016/0160-2896(84)90008-4.\n\n\nJewsbury, Paul, Stephen Bowden, and Kevin Duff. 2017. “The Cattell–Horn–Carroll Model of Cognition for Clinical Assessment.” Journal of Psychoeducational Assessment 35 (6): 547–67. https://doi.org/10.1177/0734282916651360.\n\n\nJohnson, Wendy, Thomas J Bouchard, Robert F Krueger, Matt McGue, and Irving I Gottesman. 2004. “Just One g: Consistent Results from Three Test Batteries.” Intelligence 32 (1): 95–107. https://doi.org/https://doi.org/10.1016/S0160-2896(03)00062-X.\n\n\nJohnson, Wendy, Jan te Nijenhuis, and Thomas J. Bouchard. 2008. “Still Just 1 g: Consistent Results from Five Test Batteries.” Intelligence 36 (1): 81–95. https://doi.org/https://doi.org/10.1016/j.intell.2007.06.001.\n\n\nLubinski, David. 2004. “Introduction to the Special Section on Cognitive Abilities: 100 Years After Spearman’s (1904) \"’General Intelligence,’ Objectively Determined and Measured\".” Journal of Personality and Social Psychology 86 (1): 96–111. https://doi.org/10.1037/0022-3514.86.1.96.\n\n\nMackintosh, Nicholas. 2011. IQ and Human Intelligence. OUP Oxford. https://books.google.com/books?id=BcKcAQAAQBAJ.\n\n\nMcGrew, Kevin S, DP Flanagan, JL Genshaft, and PL Harrison. 2005. Contemporary Intellectual Assessment: Theories, Tests, and Issues. The Guilford Press New York, NY, USA:\n\n\nSchneider, W Joel, Kevin S McGrew, DP Flanagan, and PL Harrison. 2012. “Contemporary Intellectual Assessment: Theories, Tests, and Issues.” Institute for Applied Psychometrics (IAP)."
  },
  {
    "objectID": "2justtests.html#the-positive-manifold",
    "href": "2justtests.html#the-positive-manifold",
    "title": "2  What do intelligence tests measure?",
    "section": "2.1 The Positive Manifold",
    "text": "2.1 The Positive Manifold\nThe positive manifold refers to the observation that all intelligence subtests, including scholastic and social intelligence tests, correlate positively. This pattern indicates that intelligence can be measured as a composite score derived from various cognitive abilities.\nThe consistency of this positive correlation, known as the g factor, has been observed even in tests initially designed to measure other traits or abilities. Since it is so easy for cognitive batteries to measure intelligence, some tests that were created with the intention of measuring more narrow abilities end up unintentionally measuring the g-factor. For example, the Cognitive Assessment System (CAS) and the Cognitive Abilities Measurement (CAM) battery were both designed to measure cognitive processes – not g, but they still measure g anyway (Keith, Kranzler, and Flanagan 2001); (Stauffer, Ree, and Carretta 1996). Confirmatory factor analysis showed that different cognitive batteries (CAB, Hawaii Battery, WAIS) were analyzed, and it turned out that the g factors computed from the three tests (five tests in Johnson 2008) were statistically indistinguishable from one another, despite the fact that the tests tapped into partly different sets of abilities (Johnson et al. 2004); (Johnson, Nijenhuis, and Bouchard 2008)."
  },
  {
    "objectID": "2justtests.html#are-intelligence-tests-reliable",
    "href": "2justtests.html#are-intelligence-tests-reliable",
    "title": "2  What do intelligence tests measure?",
    "section": "2.2 Are intelligence tests reliable?",
    "text": "2.2 Are intelligence tests reliable?\nIntelligence tests are among the most reliable and valid psychological tests and assessments and as such, they are used extensively in educational, organizational, and clinical settings (Detterman 2014).\nAccording to the Wikipedia page on IQ:\nThe most commonly used individual IQ test series is the Wechsler Adult Intelligence Scale (WAIS) for adults and the Wechsler Intelligence Scale for Children (WISC) for school-age test-takers. Other commonly used individual IQ tests (some of which do not label their standard scores as “IQ” scores) include the current versions of the Stanford–Binet Intelligence Scales, Woodcock–Johnson Tests of Cognitive Abilities…\nFor brevity, I will only focus on the first four tests mentioned: WAIS, WISC, SB5, and WJ-IV.\n\n2.2.1 Wechsler Adult Intelligence Scale (WAIS)\nAccording to a review by Climie and Rostad (2011)\n\nInternal consistency. The WAIS-IV’s reliability was measured using split-half and Cronbach’s coefficient alpha. All reported values were based on U.S. norms. The average reliability coefficients for the subtest scores ranged from acceptable (.78) to excellent (≥.90), while the four composite scores had excellent reliability coefficients (all ≥.90), with the FSIQ reporting a reliability coefficient of .98.\nTest-retest reliability. Test-retest reliabilities were obtained using Pearson’s product-moment correlation for four age bands (16-29, 30-54, 55-69, and 70-90), with time intervals between testing ranging from 8 to 82 days and a mean of 22 days. Overall, the WAIS-IV has acceptable stability across time for each of the four age bands. Subtest stability coefficients range from adequate (.74) to excellent (.90), with a majority of scores falling within the good range (.80s). Composite scores ranged from .87 to .96, with the FSIQ stability coefficient reaching an excellent value of .96.\nInterrater reliability. To ascertain acceptable levels of interrater reliability, all WAIS-IV protocols were scored by two independent scorers. General interrater agreement was high (.98 to .99), and for the verbal subtests, raters obtained excellent levels of reliability, ranging from .91 to .97.\n\n\n\n2.2.2 Wechsler Intelligence Scale for Children (WISC)\nAccording to a review by Cormier, Kennedy, and Aquilina (2016)\n\nThe formula used to calculate internal consistency reliability was recommended by Guilford (1954), Haertel (2006), and Nunnally and Bernstein (1994).\nFisher’s z transformation was used to calculate the average reliability coefficients.\nInternal consistency reliability for composite, subtest, and process scores ranges from r = .80 to r = .96.\nThe split-half method was used to calculate the reliability coefficients for all subtests, except for Coding, Symbol Search, Cancellation, Naming Speed Literacy, Naming Speed Quantity, Immediate Symbol Translation, or Delayed Symbol Translation subtests.\nThe average reliability coefficient for FSIQ is r = .96.\nThe average reliability coefficients for the primary and secondary subtests range from r = .81 to r = .94.\nThe process scores reliability coefficients range from r = .80 to r = .85.\nThe overall reliability coefficients for the primary index scores range from r = .88 to r = .93, and for the ancillary index scores range from r = .92 to r = .95.\nTest-retest reliability coefficients ranged from r = .71 to r = .94, with a mean test-retest interval of 26 days.\nEvidence of inter-scorer agreement was obtained, with the range of inter-scorer agreement being r = .98 to r = .99.\nThe average of the reliability coefficients for primary and secondary subtests from the WISC-VCDN ranges from good to excellent.\nThe reliability estimates for the WISC-VCDN scores demonstrate strong precision, which contributes to minimizing the effects of error in the measurement of the targeted abilities.\n\nAccording to a review by G. Canivez and Watkins (2016)\n\nReliability estimates of WISC-V scores reported in the WISC-V Technical and Interpretive Manual were derived using three methods: internal consistency, test-retest (stability), and interscorer agreement.\nInternal consistency was measured through the use of split-half and Cronbach’s coefficient alpha, with data provided for each of the 15 core and supplemental subtests and five composite scores (including the FSIQ).\nTest-retest reliabilities were obtained through repeated administration of the WAIS-IV, with time intervals between testing ranging from 8 to 82 days and a mean of 22 days.\nTo ascertain acceptable levels of interrater reliability, all WAIS-IV protocols were scored by two independent scorers.\nAverage coefficients across the 11 age groups for the composite scores ranged from .88 to .96 and were higher than those obtained for subtests and process scores.\nInternal consistency estimates for the primary and secondary subtests ranged from .81 to .94 while process scores ranged from .80 to .88.\nReliability estimates for the complementary subtests, process, and composite scores are provided.\nStandard errors of measurement based on reliability coefficients are presented in Table 4.4 of the WISC-V Technical and Interpretive Manual.\nShort-term test-retest stability estimates were provided for WISC-V scores where the WISC-V was twice administered to a sample of 218 children.\nInterscorer agreement ranged from .97 to .99.\n\n\n\n2.2.3 Stanford–Binet Intelligence Scales, Fifth Edition (SB-V)\nAccording to a review by Janzen, Obrzut, and Marusiak (2004)\n\nThe internal consistency (split-half reliability) for the Full Scale IQ (FSIQ), Nonverbal IQ (NVIQ), and Verbal IQ (VIQ) ranges between .95 and .98; for the five Factor Indices, it is between .90 and .92; and, for the ten subtests, it ranges between .84 and .89.\nIQ scores on the SB:V appear to be quite stable across time and less affected by practice effects.\nThe median inter-scorer correlation is .90, and correlations on multiple-point responses (0, 1, 2) range from .74 to .97.\n\n\n\n2.2.4 Woodcock–Johnson Tests of Cognitive Abilities\nAccording to a review by G. L. Canivez (2017)\n\nInternal consistency reliabilities for untimed tests and dichotomously scored items were estimated with the split-half method, whereas tests with subtests and cluster reliabilities were estimated with Mosier’s (1943) formula for unweighted composites.\nReliability for speeded tests was estimated using the test-retest method with a 1-day retest interval, and correlations were corrected for range restriction.\nMedian reliability coefficients were uniformly high: 38 of 39 were .80 or higher, and 17 were .90 or higher. Test-retest correlations for speeded tests were mostly in the .80 to .90 range.\nCluster scores include two or more tests and as such produce higher reliability estimates as predicted by true score theory. The WJ IV technical manual recommended using cluster scores in interpretation, especially when used in individual decision-making.\nModel-based reliability coefficients (omega hierarchical) could be assessed to determine unique true score variance captured by the different scores.\nAlternate forms equivalence was examined and item difficulty and content were found to be similar among the forms.\n\nAccording to Madle (2017)\n\nMedian internal consistency coefficient for WJ IV COG GIA score is .97, with median coefficients of .95 to .97 for different age groups\nGf-Gc reliability coefficients range from .94 to .98 (median = .96)\nBIA reliability coefficient median is .94 (.92-.95)\nMedian coefficients for the various cognitive clusters range from .86 (Visual Processing) to .91 (Short-Term Working Memory)\nOral Language reliability coefficients range from .89 for Oral Expression to .92 for Broad Oral Language\nAcademic cluster median reliability coefficients range from .92 to .97, with a Broad Achievement score median reliability coefficient of .99\nTest-retest studies were completed for speeded tests only, and median reliability coefficients ranged from .88 to .92 for three different age groups\nEquivalence of item difficulties and item content for the achievement forms was examined and found to be strong."
  },
  {
    "objectID": "2justtests.html#are-intelligence-tests-statistically-valid",
    "href": "2justtests.html#are-intelligence-tests-statistically-valid",
    "title": "2  What do intelligence tests measure?",
    "section": "2.3 Are intelligence tests statistically valid?",
    "text": "2.3 Are intelligence tests statistically valid?\nTo be added: test validity- too much to add rn\n\n2.3.1 Wechsler Adult Intelligence Scale (WAIS)\n\n\n2.3.2 Wechsler Intelligence Scale for Children (WISC)\n\n\n2.3.3 Stanford–Binet Intelligence Scales, Fifth Edition (SB-V)\n\n\n2.3.4 Woodcock–Johnson Tests of Cognitive Abilities\n\n\n\n\nCanivez, G. L. 2017. “Test Review of Woodcock-Johnson® IV.” In The Twentieth Mental Measurements Yearbook, edited by J. F. Carlson, K. F. Geisinger, and J. L. Jonson.\n\n\nCanivez, Gary, and Marley Watkins. 2016. “Review of the Wechsler Intelligence Scale for Children–Fifth Edition: Critique, Commentary, and Independent Analyses.” In, 683–702.\n\n\nClimie, Emma A., and Kristin Rostad. 2011. “Test Review: Wechsler Adult Intelligence Scale.” Journal of Psychoeducational Assessment 29 (6): 581–86. https://doi.org/10.1177/0734282911408707.\n\n\nCormier, Damien C., Kathleen E. Kennedy, and Alexandra M. Aquilina. 2016. “Test Review: Wechsler Intelligence Scale for Children, Fifth Edition: Canadian 322 (WISC-VCDN) by d. Wechsler.” Canadian Journal of School Psychology 31 (4): 322–34. https://doi.org/10.1177/0829573516648941.\n\n\nDetterman, Douglas K. 2014. “You Should Be Teaching Intelligence!” Intelligence 42: 148–51. https://doi.org/https://doi.org/10.1016/j.intell.2013.07.021.\n\n\nJanzen, Henry L., John E. Obrzut, and Christopher W. Marusiak. 2004. “Test Review: Roid, g. H. (2003). Stanford-Binet Intelligence Scales, Fifth Edition (SB:v). Itasca, IL: Riverside Publishing.” Canadian Journal of School Psychology 19 (1-2): 235–44. https://doi.org/10.1177/082957350401900113.\n\n\nJohnson, Wendy, Thomas J Bouchard, Robert F Krueger, Matt McGue, and Irving I Gottesman. 2004. “Just One g: Consistent Results from Three Test Batteries.” Intelligence 32 (1): 95–107. https://doi.org/https://doi.org/10.1016/S0160-2896(03)00062-X.\n\n\nJohnson, Wendy, Jan te Nijenhuis, and Thomas J. Bouchard. 2008. “Still Just 1 g: Consistent Results from Five Test Batteries.” Intelligence 36 (1): 81–95. https://doi.org/https://doi.org/10.1016/j.intell.2007.06.001.\n\n\nKeith, Timothy, John Kranzler, and Dawn Flanagan. 2001. “What Does the Cognitive Assessment System (CAS) Measure? Joint Confirmatory Factor Analysis of the CAS and the Woodcock-Johnson Tests of Cognitive Ability.” School Psychology Review 30 (March): 89–119. https://doi.org/10.1080/02796015.2001.12086102.\n\n\nMadle, R. A. 2017. “[Test Review of Woodcock-Johnson® IV].” In The Twentieth Mental Measurements Yearbook, edited by J. F. Carlson, K. F. Geisinger, and J. L. Jonson.\n\n\nStauffer, Joseph M., Malcolm James Ree, and Thomas R. Carretta. 1996. “Cognitive-Components Tests Are Not Much More Than g: An Extension of Kyllonen’s Analyses.” The Journal of General Psychology 123 (3): 193–205. https://doi.org/10.1080/00221309.1996.9921272.\n\n\nVan der Maas, Han L. J., Kees-Jan Kan, and Denny Borsboom. 2014. “Intelligence Is What the Intelligence Test Measures. Seriously.” Journal of Intelligence 2 (1): 12–15. https://doi.org/10.3390/jintelligence2010012."
  },
  {
    "objectID": "3trustworthy.html#isnt-the-field-of-psychology-unreliable",
    "href": "3trustworthy.html#isnt-the-field-of-psychology-unreliable",
    "title": "3  Are intelligence tests trusted?",
    "section": "3.1 Isn’t the field of psychology unreliable?",
    "text": "3.1 Isn’t the field of psychology unreliable?\nPsychology, among other fields, should absolutely be worried about the replication crisis. However, some scientific fields and disciplines are more affected than others. For example, cognitive psychology at large has double the replication rate than social psychology. Cognitive Psychology. (Open Science Collaboration 2015)\nIn general, ‘g’ is “probably the best measured and most studied human trait in all of psychology”. (Gottfredson 2002, 25) Another prominent researcher on psychology of intelligence calls the general intelligence factor “certainly the most robust phenomenon in the social sciences,” and adds: “Despite torturous method of factor analysis, attacks from outraged critics and even long periods of being ignored, g [general intelligence] just keeps reappearing like the insistent relative that won’t go away” (Detterman 2000, 136). This guy is also the founder of the journal Intelligence so he’s a very mainstream voice in this discussion.\n(Haier 2019) states that in the field of intelligence, “there is no replication crisis about key empirical findings.” In general, “g is regarded as “perhaps the most replicated result in psychology” (Deary 2000, 318)."
  },
  {
    "objectID": "3trustworthy.html#evidences-of-test-bias-in-intelligence-tests",
    "href": "3trustworthy.html#evidences-of-test-bias-in-intelligence-tests",
    "title": "3  Are intelligence tests trusted?",
    "section": "3.2 Evidences of test bias in intelligence tests",
    "text": "3.2 Evidences of test bias in intelligence tests\nThere has been much debate around the potential bias of intelligence tests. However, research has consistently shown that intelligence tests, when administered and scored correctly, are not biased against any particular group or population.\nIn fact, intelligence tests are designed to be culturally fair and measure cognitive abilities that are not tied to any specific cultural or socioeconomic group. The tests are created using a rigorous process that involves extensive pilot testing, item analysis, and psychometric evaluation.\nExpert opinion finds that “the issue of test bias is scientifically dead” (Hunter and Schmidt 2000, 151) “There exists, in contrast to the position of the late 1960s, a substantial body of research addressing the cultural test bias hypothesis, and scholars have extensively reviewed this literature in book and chapter-length forums (A. R. Jensen 1980); (Cecil R. Reynolds 1995); (Cecil R. Reynolds 1998); (Cecil R. Reynolds and Brown 1984). Essentially, these reviews have concluded that well-constructed, reliable, well-standardized psychological tests are not biased against native-born American racial or ethnic minorities. Studies of cultural bias in testing do occasionally reveal bias in some aspects of validity, but the bias is more likely to favor minorities in a predictive context” (Cecil R. Reynolds 2000);(Cecil R. Reynolds and Suzuki 2012)\nIn 1982, the National Research Council and the National Academy of Sciences found that “ability tests predict equally well for all groups of test takers. Research evidence does not support the notion that tests systematically underpredict the performance of minority group members” (Wigdor 1982) In 1994, Mainstream Science on Intelligence, a statement issued by several researchers, finds that “Intelligence tests are not culturally biased against American blacks or other native-born, English-speaking peoples in the U.S. Rather, IQ scores predict equally accurately for all such Americans, regardless of race and social class. Individuals who do not understand English well can be given either a nonverbal test or one in their native language.” (Gottfredson 1997). In 1996, the American Psychological Association found that “considered as predictors of future performance, the tests do not seem to be biased against African Americans.” (Neisser et al. 1996). (Reeve and Charles 2008) found that there is a consensus among intelligence experts that cognitive ability tests are not bias against minority groups\nAnd most important of all: logical and empirical examination: If intelligence tests merely measure knowledge or conformity to Western middle-class culture is the fact that the racial group with the highest average on these tests is not Europeans, but East Asians; this has been true since the 1920s (Goodenough 1926). If intelligence tests measure acculturation to Western culture, then indigenous communities who have had more contact with Europeans should score higher than people in communities in the same nation who have had less contact. However, this is not the case (Porteus 1965).\nContent of many test formats (e.g., matrix tests, digit span) contains very little information that is unique to Western culture. It is not clear how numbers or geometric patterns are special to Western middle-class individuals. Expert rated culturally loaded test items do not contribute to an increase in the Black/White divide. (Arthur R. Jensen and McGurk 1987) If test items were culturally loaded, (especially to a degree that would significantly change test results) this would mean test items ranked by difficulty would not correlate well by race. However, the opposite is true. (Cecil R. Reynolds and Suzuki 2012) Correlation of rank order difficulty between cognitive batteries is nearly perfect among Blacks and Whites."
  },
  {
    "objectID": "3trustworthy.html#evidences-regarding-stereotype-threat-in-intelligence-tests",
    "href": "3trustworthy.html#evidences-regarding-stereotype-threat-in-intelligence-tests",
    "title": "3  Are intelligence tests trusted?",
    "section": "3.3 Evidences regarding stereotype threat in intelligence tests",
    "text": "3.3 Evidences regarding stereotype threat in intelligence tests\nRacial bias\nThe literature on stereotype threat is not great. (Schimmack 2017) We have even had papers that are completely fabricated (probably for political motivation). (Flores et al. 2021) We have a few meta analyses on this phenomenon. Publication bias plagues many of these studies and when factored for, the effect sizes decrease. (Flore and Wicherts 2015);(Shewach, Sackett, and Quint 2019), a meta-analysis of 212 experimental studies on stereotype threat, which included a total of more than 10,000 adult participants effects (the largest to date) ‘range[d] from negligible to small’ If we assume stereotype threat is an actual possible influential factor, we would actually expect Black people to have increased scores as they measure higher than whites on various psychological metrics\nCompared to Whites, Blacks have higher self-esteem (Twenge and Crocker 2002), Lower suicide rates (Curtin, Brown, and Jordan 2022), Lower rates of stress (Krueger, Saint Onge, and Chang 2011), Lower risk for panic disorder, Lower risk for generalized anxiety order, Lower risk for social phobia (Breslau et al. 2006), Lower rates for depressive disorder (Riolo et al. 2005), Lower overall rate of mental disorders (Coleman et al. 2016). Since Black people are more confident and mentally healthy, it doesn’t seem like stereotype threat could be a relevant factor. In conclusion: the evidence points to there being no cultural bias in IQ testing and there doesn’t seem to be enough methodologically robust literature to make a certain claim on stereotype threat (though more recent analyses that factor for publication bias show null effects). The burden of proof rests on those who claim this to significantly affect the gap between blacks and whites."
  },
  {
    "objectID": "3trustworthy.html#do-scientists-actually-believe-in-general-intelligence",
    "href": "3trustworthy.html#do-scientists-actually-believe-in-general-intelligence",
    "title": "3  Are intelligence tests trusted?",
    "section": "3.4 Do scientists actually believe in general intelligence?",
    "text": "3.4 Do scientists actually believe in general intelligence?\nThe theory of IQ as the measure of general intelligence is mainstream. The American Psychological Association’s authoritative task force on intelligence stated that the theory of general intelligence is “the most widely accepted current view” (Neisser et al. 1996, 81).\nFifty-eight percent of APA respondents favor some form of a general intelligence solution, whereas 13% feel separate faculties are superior. Only 16% think the data are sufficiently ambiguous as to not favor either solution. (Snyderman and Rothman 1987, 140)\nMainstream Science on Intelligence, a Wallstreet Journal editorial with 52 signatories of 25 conclusions that represent the mainstream, Gottfredson writes that “Intelligence is a very general mental capability … it reflects a broader and deeper capability for comprehending our surroundings …” Of the invitation sent out to 131 researchers, only 11 responded that one or more of the conclusions did not represent the mainstream. (Gottfredson 1997)\nIn a conference attended by leading experts on human intelligence Michael Rutter, who is known for his moderate views, said: “All of us accept [g’s] reality. It is not merely a statistical artifact, rather, it really does represent something that is biologically important” (Rutter 2000, 282). One of the most prominent critics of general intelligence had to concede: “The evidence in favor of a general factor of intelligence is, in one sense, overwhelming … One would have to be blind or intransigent not to give this evidence its due” (Sternberg 2003, 375)\nMost recently, a survey of expert opinion on intelligence finds that “76% favored a general factor perspective” noting that “Experts favored a g factor perspective” (Rindermann, Becker, and Coyle 2020, 4)\n\n\n\n\nBreslau, Joshua, Sergio Aguilar-Gaxiola, Kenneth S. Kendler, Maxwell Su, David Williams, and Ronald C. Kessler. 2006. “Specifying Race-Ethnic Differences in Risk for Psychiatric Disorder in a USA National Sample.” Psychological Medicine 36 (1): 57–68. https://doi.org/10.1017/S0033291705006161.\n\n\nColeman, Karen J., Christine Stewart, Beth E. Waitzfelder, John E. Zeber, Leo S. Morales, Ameena T. Ahmed, Brian K. Ahmedani, et al. 2016. “Racial-Ethnic Differences in Psychiatric Diagnoses and Treatment Across 11 Health Care Systems in the Mental Health Research Network.” Psychiatric Services 67 (7): 749–57. https://doi.org/10.1176/appi.ps.201500217.\n\n\nCurtin, Sally C, Kamiah A Brown, and Mariah E Jordan. 2022. “Suicide Rates for the Three Leading Methods by Race and Ethnicity : United States, 2000–2020.” NCHS Data Brief ; No. 450. https://dx.doi.org/10.15620/cdc:121798; National Center for Health Statistics.\n\n\nDeary, I. J. 2000. Looking down on Human Intelligence: From Psychometrics to the Brain. Oxford Psychology Series. Oxford University Press. https://books.google.com/books?id=GJcQAQAAIAAJ.\n\n\nDetterman, D K. 2000. “General Intelligence and the Definition of Phenotypes.” Novartis Foundation Symposium 233: 136-144; discussion 144-8. https://doi.org/10.1002/0470870850.ch9.\n\n\nFlore, Paulette C., and Jelte M. Wicherts. 2015. “Does Stereotype Threat Influence Performance of Girls in Stereotyped Domains? A Meta-Analysis.” Journal of School Psychology 53 (1): 25–44. https://doi.org/https://doi.org/10.1016/j.jsp.2014.10.002.\n\n\nFlores, AJ, TA Chavez, N Bolger, and BJ Casad. 2021. “Retraction Notice.” Personality and Social Psychology Bulletin 47 (1): 161–61. https://doi.org/10.1177/0146167220973962.\n\n\nGoodenough, FL. 1926. “Racial Differences in the Intelligence of School Children.” Journal of Experimental Psychology 9 (4): 388–97. https://doi.org/10.1037/h0073325.\n\n\nGottfredson, Linda S. 1997. “Mainstream Science on Intelligence: An Editorial with 52 Signatories, History, and Bibliography.” Intelligence 24 (1): 13–23. https://doi.org/https://doi.org/10.1016/S0160-2896(97)90011-8.\n\n\n———. 2002. “G: Highly General and Highly Practical.” In The General Factor of Intelligence: How General Is It?, 331–80. Mahwah, NJ, US: Lawrence Erlbaum Associates Publishers. https://doi.org/10.4324/9781410613165.\n\n\nHaier, Richard J. 2019. “Alive and Well, Intelligence Research on the Move.” The American Journal of Psychology 132 (2): 259–62. https://doi.org/10.5406/amerjpsyc.132.2.0259.\n\n\nHunter, John E, and Frank L Schmidt. 2000. “Racial and Gender Bias in Ability and Achievement Tests: Resolving the Apparent Paradox.” Psychology, Public Policy, and Law 6 (1): 151–58. https://doi.org/10.1037/1076-8971.6.1.151.\n\n\nJensen, A. R. 1980. Bias in Mental Testing. Free Press. https://books.google.com/books?id=wJR9AAAAMAAJ.\n\n\nJensen, Arthur R., and Frank C. J. McGurk. 1987. “Black-White Bias in ‘Cultural’ and ‘Noncultural’ Test Items.” Personality and Individual Differences 8 (3): 295–301. https://doi.org/https://doi.org/10.1016/0191-8869(87)90029-8.\n\n\nKrueger, Patrick M, Jarron M Saint Onge, and Virginia W Chang. 2011. “Race/Ethnic Differences in Adult Mortality: The Role of Perceived Stress and Health Behaviors.” Social Science & Medicine 73 (9): 1312–22. https://doi.org/10.1016/j.socscimed.2011.08.007.\n\n\nNeisser, Ulric, Gwyneth Boodoo, Thomas J. Bouchard Jr., A. Wade Boykin, Nathan Brody, Stephen J. Ceci, Diane F. Halpern, et al. 1996. “Intelligence: Knowns and Unknowns.” American Psychologist 51 (2): 77–101. https://doi.org/10.1037/0003-066X.51.2.77.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” Science 349 (6251): aac4716. https://doi.org/10.1126/science.aac4716.\n\n\nPorteus, SD. 1965. Porteus Maze Test; Fifty Years’ Application. Pacific Books.\n\n\nReeve, Charlie L., and Jennifer E. Charles. 2008. “Survey of Opinions on the Primacy of g and Social Consequences of Ability Testing: A Comparison of Expert and Non-Expert Views.” Intelligence 36 (6): 681–88. https://doi.org/https://doi.org/10.1016/j.intell.2008.03.007.\n\n\nReynolds, Cecil R. 2000. “Why Is Psychometric Research on Bias in Mental Testing so Often Ignored?” Psychology, Public Policy, and Law 6 (1): 144–50. https://doi.org/10.1037/1076-8971.6.1.144.\n\n\nReynolds, Cecil R. 1995. “Test Bias and the Assessment of Intelligence and Personality.” In International Handbook of Personality and Intelligence, edited by Donald H. Saklofske and Moshe Zeidner, 545–73. Boston, MA: Springer US. https://doi.org/10.1007/978-1-4757-5571-8_25.\n\n\n———. 1998. “10.03 - Cultural Bias in Testing of Intelligence and Personality.” In Comprehensive Clinical Psychology, edited by Alan S. Bellack and Michel Hersen, 53–92. Oxford: Pergamon. https://doi.org/https://doi.org/10.1016/B0080-4270(73)00105-X.\n\n\nReynolds, Cecil R., and Robert T. Brown. 1984. “Bias in Mental Testing.” In Perspectives on Bias in Mental Testing, edited by Cecil R. Reynolds and Robert T. Brown, 1–39. Boston, MA: Springer US. https://doi.org/10.1007/978-1-4684-4658-6_1.\n\n\nReynolds, Cecil R., and Lisa A. Suzuki. 2012. “Bias in Psychological Assessment.” In Handbook of Psychology, Second Edition. John Wiley & Sons, Ltd. https://doi.org/https://doi.org/10.1002/9781118133880.hop210004.\n\n\nRindermann, Heiner, David Becker, and Thomas R. Coyle. 2020. “Survey of Expert Opinion on Intelligence: Intelligence Research, Experts’ Background, Controversial Issues, and the Media.” Intelligence 78: 101406. https://doi.org/https://doi.org/10.1016/j.intell.2019.101406.\n\n\nRiolo, Stephanie A., Tuan Anh Nguyen, John F. Greden, and Cheryl A. King. 2005. “Prevalence of Depression by Race/Ethnicity: Findings from the National Health and Nutrition Examination Survey III.” American Journal of Public Health 95 (6): 998–1000. https://doi.org/10.2105/AJPH.2004.047225.\n\n\nRutter, Michael. 2000. “Closing Remarks.” In The Nature of Intelligence, 281–87. John Wiley & Sons, Ltd. https://doi.org/https://doi.org/10.1002/0470870850.ch18.\n\n\nSchimmack, Ulrich. 2017. “Hidden Figures: Replication Failures in the Stereotype Threat Literature.” https://replicationindex.com/2017/04/07/hidden-figures-replication-failures-in-the-stereotype-threat-literature/.\n\n\nShewach, Oren R, Paul R Sackett, and Sander Quint. 2019. “Stereotype Threat Effects in Settings with Features Likely Versus Unlikely in Operational Test Settings: A Meta-Analysis.” Journal of Applied Psychology 104 (12): 1514–34. https://doi.org/10.1037/apl0000420.\n\n\nSnyderman, Mark, and Stanley Rothman. 1987. “Survey of Expert Opinion on Intelligence and Aptitude Testing.” American Psychologist 42: 137–44. https://doi.org/10.1037/0003-066X.42.2.137.\n\n\nSternberg, Robert J. 2003. “Chapter 17 - ‘My House Is a Very Very Very Fine House’ —but It Is Not the Only House.” In The Scientific Study of General Intelligence, edited by Helmuth Nyborg, 373–95. Oxford: Pergamon. https://doi.org/https://doi.org/10.1016/B978-008043793-4/50056-8.\n\n\nTwenge, Jean M, and Jennifer Crocker. 2002. “Race and Self-Esteem: Meta-Analyses Comparing Whites, Blacks, Hispanics, Asians, and American Indians and Comment on Gray-Little and Hafdahl (2000).” Psychological Bulletin 128 (3): 371–408. https://doi.org/10.1037/0033-2909.128.3.371.\n\n\nWigdor, Alexandra K. 1982. “Ability Testing: Uses, Consequences, and Controversies.” Educational Measurement: Issues and Practice 1 (3): 6–8. https://doi.org/https://doi.org/10.1111/j.1745-3992.1982.tb00659.x."
  },
  {
    "objectID": "4notuseful.html#threshold-hypothesis",
    "href": "4notuseful.html#threshold-hypothesis",
    "title": "4  Are IQ tests even useful?",
    "section": "4.1 Threshold hypothesis",
    "text": "4.1 Threshold hypothesis\nThe “threshold hypothesis” states that increased IQ does not lead to additional benefits- though the actual line of the threshold is disputed. (Gladwell 2008) states that the threshold is at an IQ of 120 (which would mean mathematically that over 90 percent of the population experience noticeable benefits with higher IQ). A different estimate by (Feldman 1984) says that the threshold is about IQ 150 (which excludes less than 1 percent of the population).\nBased on the best available research, the threshold hypothesis is incorrect. Data from large samples of high-IQ people show that the likelihood of beneficial life outcomes continues to increase as people get smarter. The best research on the threshold hypothesis comes from SMPY. In the SMPY sample, there are over 2,300 people who have IQs of 135 or higher – the top 1% of the population. Even within this bright group, IQ was positively correlated with favorable work and educational outcomes. For sample members in the top quarter of the top 1%, the odds of earning a doctorate were 3.56 times higher than for people whose IQ was “only” in the bottom quarter of the top 1%. In the SMPY sample, the odds of a person in the brighter group were also higher for having an income in the top 5% of incomes nationwide (2.31 times greater); earning a patent (3.01 times greater); publishing a literary work (4.55 times greater); and publishing scholarly work in science, technology, engineering, or mathematics (4.97 times greater). There was no apparent threshold where the probability of any accomplishments leveled off or decreased (Lubinski 2009). Selecting an even higher threshold of an IQ of 156 (the top 0.01% of the population, or the top 1 in 10,000 people) does not diminish the threshold effect. Over 50% of SMPY sample members with IQs of 156 or higher earned doctorates, while “only” 30% of the top 0.5% (IQ of 139 or higher) earned a doctorate (Lubinski 2009) (In comparison, 1.8% of the US adult population has earned a doctorate).\nMoreover, people with IQ scores in the top 1 in 10,000 rise to the top echelons of leadership and productivity in their careers at such a high rate that, “many are outstanding creators of modern culture, constituting a precious human-capital resource” (Kell, Lubinski, and Benbow 2013, 648). The results of SMPY have been replicated. (Wai 2014, 76) found that within a sample of 1,536 teenagers with IQ scores in the top 1% (IQ of 135 or higher), the smartest 25% earned doctorates at a rate that was 1.52 times. greater than the least intelligent 25%. Another sample of individuals with IQs in the top 1 in 10,000 of the population had similar levels of high education achievement, work productivity, and eminence within their fields as was found in the SMPY sample (Makel et al. 2016). (Coyle 2015) reported data from two studies on the relationship between intelligence and college grade point averages and found that the correlation was constant across the entire range of intelligence levels. In other words, there was no point at which greater levels of intelligence failed to increase the probability of a high grade point average in college. In a sample of gifted children, (Ruf 2005) found that as IQ increased, children were better able to move through the K-12 curriculum quickly and were increasingly more likely to display early academic development, such as learning to read by age. Successively brighter groups also mastered advanced academic material at younger and younger ages. Another study that disproves the threshold hypothesis showed that in a large sample of medical school graduates higher scores on achievement tests needed to obtain a medical license were always associated with higher levels of competence in practice (Wakeford et al. 2018)."
  },
  {
    "objectID": "4notuseful.html#arent-people-with-higher-iqs-more-likely-to-be-mentally-ill",
    "href": "4notuseful.html#arent-people-with-higher-iqs-more-likely-to-be-mentally-ill",
    "title": "4  Are IQ tests even useful?",
    "section": "4.2 Aren’t people with higher IQs more likely to be mentally ill?",
    "text": "4.2 Aren’t people with higher IQs more likely to be mentally ill?\nFor social and emotional outcomes, there is not much evidence about whether an IQ threshold exists. In the best study on this topic (Guldemond et al. 2007), children above IQs of 130 and 144 did not have more social or emotional problems than children with IQs in the 110s and 120s. Ironically, the evidence indicates that high intelligence may be a protective factor against at least some forms of psychiatric illness (Savage et al. 2018); (Walker et al. 2002). This is especially apparent in GWAS results, which show that some of the DNA segments associated with higher IQ are often negatively correlated with mental health problems (Hill et al. 2019); (Savage et al. 2018); (Sniekers et al. 2017), which makes it especially unlikely that people with very high IQs experience more psychiatric illnesses. An important exception to this general trend is autism spectrum disorder, which seems to share some genes in common with high intelligence (Hill et al. 2019); (Savage et al. 2018); (Sniekers et al. 2017). (Williams et al. 2022) finds that high intelligence is not a risk factor for mental health disorders"
  },
  {
    "objectID": "4notuseful.html#do-iq-score-actually-predict-anything",
    "href": "4notuseful.html#do-iq-score-actually-predict-anything",
    "title": "4  Are IQ tests even useful?",
    "section": "4.3 Do IQ score actually predict anything?",
    "text": "4.3 Do IQ score actually predict anything?\n(strenze2015?) charts all meta-analyses of correlates with intelligence. IQ predicts many things despite the test not being created to predict these things.\n\n\n\n\nCoyle, Thomas R. 2015. “Relations Among General Intelligence (g), Aptitude Tests, and GPA: Linear Effects Dominate.” Intelligence 53: 16–22. https://doi.org/https://doi.org/10.1016/j.intell.2015.08.005.\n\n\nFeldman, David Henry. 1984. “A Follow-up of Subjects Scoring Above 180 IQ in Terman’s ‘Genetic Studies of Genius’.” Exceptional Children 50 (6): 518–23. https://doi.org/10.1177/001440298405000604.\n\n\nGladwell, M. 2008. Outliers: The Story of Success. Penguin Books Limited. https://books.google.com/books?id=ialrgIT41OAC.\n\n\nGuldemond, Henk, Roel Bosker, Hans Kuyper, and Greetje van der Werf. 2007. “Do Highly Gifted Students Really Have Problems?” Educational Research and Evaluation 13 (6): 555–68. https://doi.org/10.1080/13803610701786038.\n\n\nHill, W. D., R. E. Marioni, O. Maghzian, S. J. Ritchie, S. P. Hagenaars, A. M. McIntosh, C. R. Gale, G. Davies, and I. J. Deary. 2019. “A Combined Analysis of Genetically Correlated Traits Identifies 187 Loci and a Role for Neurogenesis and Myelination in Intelligence.” Molecular Psychiatry 24 (2): 169–81. https://doi.org/10.1038/s41380-017-0001-5.\n\n\nKell, Harrison J., David Lubinski, and Camilla P. Benbow. 2013. “Who Rises to the Top? Early Indicators.” Psychological Science 24 (5): 648–59. https://doi.org/10.1177/0956797612457784.\n\n\nLubinski, David. 2009. “Exceptional Cognitive Ability: The Phenotype.” Behavior Genetics 39: 350–58. https://doi.org/10.1007/s10519-009-9273-0.\n\n\nMakel, Matthew C., Harrison J. Kell, David Lubinski, Martha Putallaz, and Camilla P. Benbow. 2016. “When Lightning Strikes Twice: Profoundly Gifted, Profoundly Accomplished.” Psychological Science 27 (7): 1004–18. https://doi.org/10.1177/0956797616644735.\n\n\nRuf, D. L. 2005. Losing Our Minds: Gifted Children Left Behind. Great Potential Press. https://books.google.com/books?id=RnWY5TCJr1QC.\n\n\nSavage, Jeanne E., Philip R. Jansen, Sven Stringer, Kyoko Watanabe, Julien Bryois, Christiaan A. de Leeuw, Mats Nagel, et al. 2018. “Genome-Wide Association Meta-Analysis in 269,867 Individuals Identifies New Genetic and Functional Links to Intelligence.” Nature Genetics 50 (7): 912–19. https://doi.org/10.1038/s41588-018-0152-6.\n\n\nSniekers, Suzanne, Sven Stringer, Kyoko Watanabe, Philip R. Jansen, Jonathan R. I. Coleman, Eva Krapohl, Erdogan Taskesen, et al. 2017. “Genome-Wide Association Meta-Analysis of 78,308 Individuals Identifies New Loci and Genes Influencing Human Intelligence.” Nature Genetics 49 (7): 1107–12. https://doi.org/10.1038/ng.3869.\n\n\nWai, Jonathan. 2014. “Experts Are Born, Then Made: Combining Prospective and Retrospective Longitudinal Data Shows That Cognitive Ability Matters.” Intelligence 45: 74–80. https://doi.org/https://doi.org/10.1016/j.intell.2013.08.009.\n\n\nWakeford, Richard, Kasia Ludka, Katherine Woolf, and I. C. McManus. 2018. “Fitness to Practise Sanctions in UK Doctors Are Predicted by Poor Performance at MRCGP and MRCP(UK) Assessments: Data Linkage Study.” BMC Medicine 16: 230. https://doi.org/10.1186/s12916-018-1214-4.\n\n\nWalker, Nicholas P, Pauline M McConville, David Hunter, Ian J Deary, and Lawrence J Whalley. 2002. “Childhood Mental Ability and Lifetime Psychiatric Contact: A 66-Year Follow-up Study of the 1932 Scottish Mental Ability Survey.” Intelligence 30 (3): 233–45. https://doi.org/https://doi.org/10.1016/S0160-2896(01)00098-8.\n\n\nWilliams, Camille Michèle, Hugo Peyre, Ghislaine Labouret, Judicael Fassaya, Adoración Guzmán Garcı́a, Nicolas Gauvrit, and Franck Ramus. 2022. “High Intelligence Is Not a Risk Factor for Mental Health Disorders.” medRxiv. https://doi.org/10.1101/2022.05.26.22275621."
  },
  {
    "objectID": "5sesfactors.html",
    "href": "5sesfactors.html",
    "title": "5  Aren’t people are low IQ because they’re poor?",
    "section": "",
    "text": "Firstly, we have to understand that IQ is designed to be a measurement of intelligence. Like all models, it is subject to noise. The interplay between intelligence and socioeconomic status is complicated and should be treated as such. Firstly, we know that intelligence and socioeconomic status correlate but this, however, does not necessarily imply causation in any specific direction.\n(Sirin 2005) meta-analyzed data on roughly 100,000 students and found the mean correlation between cognitive ability and parental SES to be .28, indicating a moderate relationship. (Neisser et al. 1996) from the American Psychological Association task force report on intelligence explains that these two variables influence each other. A meta-analytic review of the longitudinal research on IQ and SES, found that the mean correlations between a person’s IQ measured at one point and their education, occupation status, and income, measured 10 or more years later, were .49, .41, and .22 respectively. This is significant because they were better predictors than their parental socioeconomic status. (Strenze 2007); (Murray 1998) analyzed data from the NLSY and showed that IQ differences within sibling pairs predicted future differences in SES. That is, the sibling with a higher IQ typically ended up having more education, a higher status occupation, and more income.\nBecause siblings have identical parental SES, this analysis shows that IQ leads to higher SES independent of parental SES. This is also recorded in (Lubinski 2009).\nTwin studies can additionally give insight on the variation of intelligence attributed to the common or shared environment. Common environmental influence, which includes familial socioeconomic status, influences 25 percent the variability and decreases to around 15 percent of the variability in young adulthood- the maximum amount of influence that socioeconomic factors from family could play. (Haworth et al. 2010)\nActing as a natural experiment, some evidence shows that adoption may raise IQ since adoption into a highly favorable environment would be described as an “intensive, years-long intervention that includes academic, social, and health improvements throughout childhood and adolescence” (Warne 2020) However, this kind of adoption as stated above seems to increase IQ scores of around 4 points. (Kendler et al. 2015) (though this may not be in g itself (te Nijenhuis, Jongeneel-Grimen, and Armstrong 2015)). More generally, (McGue et al. 2007) studies adoptive and non adoptive families, each consisting of an adolescent sibling pair and one or both of their parents (with comparable age and gender). This study does not find that socioeconomic status is a causal element in determining intelligence.\n\n\n\n\nHaworth, C. M. A., M. J. Wright, M. Luciano, N. G. Martin, E. J. C. de Geus, C. E. M. van Beijsterveldt, M. Bartels, et al. 2010. “The Heritability of General Cognitive Ability Increases Linearly from Childhood to Young Adulthood.” Molecular Psychiatry 15 (11): 1112–20. https://doi.org/10.1038/mp.2009.55.\n\n\nKendler, Kenneth S., Eric Turkheimer, Henrik Ohlsson, and Kristina Sundquist. 2015. “Family Environment and the Malleability of Cognitive Ability: A Swedish National Home-Reared and Adopted-Away Cosibling Control Study.” Edited by Richard E. Nisbett. Proceedings of the National Academy of Sciences 112 (15): 4612–17. https://doi.org/10.1073/pnas.1417106112.\n\n\nLubinski, David. 2009. “Cognitive Epidemiology: With Emphasis on Untangling Cognitive Ability and Socioeconomic Status.” Intelligence 37: 625–33. https://doi.org/10.1016/j.intell.2009.09.001.\n\n\nMcGue, Matt, Margaret Keyes, Anu Sharma, Irene Elkins, Lisa Legrand, Wendy Johnson, and William G. Iacono. 2007. “The Environments of Adopted and Non-Adopted Youth: Evidence on Range Restriction from the Sibling Interaction and Behavior Study (SIBS).” Behavior Genetics 37 (3): 449–62. https://doi.org/10.1007/s10519-007-9142-7.\n\n\nMurray, C. A. 1998. Income Inequality and IQ. AEI Studies on Understanding e. AEI Press. https://books.google.com/books?id=rrdNL4dpijwC.\n\n\nNeisser, Ulric, Gwyneth Boodoo, Thomas J. Bouchard Jr., A. Wade Boykin, Nathan Brody, Stephen J. Ceci, Diane F. Halpern, et al. 1996. “Intelligence: Knowns and Unknowns.” American Psychologist 51 (2): 77–101. https://doi.org/10.1037/0003-066X.51.2.77.\n\n\nSirin, Selcuk R. 2005. “Socioeconomic Status and Academic Achievement: A Meta-Analytic Review of Research.” Review of Educational Research 75: 417–53. https://doi.org/10.3102/00346543075003417.\n\n\nStrenze, Tarmo. 2007. “Intelligence and Socioeconomic Success: A Meta-Analytic Review of Longitudinal Research.” Intelligence 35 (5): 401–26. https://doi.org/https://doi.org/10.1016/j.intell.2006.09.004.\n\n\nte Nijenhuis, Jan, Birthe Jongeneel-Grimen, and Elijah L. Armstrong. 2015. “Are Adoption Gains on the g Factor? A Meta-Analysis.” Personality and Individual Differences 73: 56–60. https://doi.org/https://doi.org/10.1016/j.paid.2014.09.022.\n\n\nWarne, R. T. 2020. In the Know: Debunking 35 Myths about Human Intelligence. Cambridge University Press. https://books.google.com/books?id=TtX7DwAAQBAJ."
  },
  {
    "objectID": "6statartifact.html",
    "href": "6statartifact.html",
    "title": "6  Isn’t g a statistical artifact?",
    "section": "",
    "text": "There are many cognitive batteries that specifically do not try to look for ‘g’, some of which expressly try to avoid it.\n\nResearchers for the British Ability Scales lament that “there is little evidence that strong primary factors… have accounted for any substantial proportion of the common variance of the British Ability Scales. This is despite the fact that the scales sample a wide range of psychological functions.” It asks What, then, are we to make of the results of these analyses? Do they mean that we are back to square one, as it were, and that after 60 years of research we have turned full circle and are back with the theories of Spearman?” (Elliott 1986).\nThe CAS Battery is based on the Soviet inspired PASS theory which disavows g and asserts that intelligence consists of four processes called Planning, Attention-Arousal, Simultaneous, and Successive. The CAS was designed to assess these four processes. However, Keith el al. 2001 did a joint confirmatory factor analysis of the CAS together with the WJ-III battery, concluding that not only does the CAS not measure the constructs it was designed to measure, but that notwithstanding the test makers’ aversion to g, the g factor derived from the CAS is large and statistically indistinguishable from the g factor of the WJ-III. The CAS therefore appears to be the opposite of what it was supposed to be: an excellent test of the “non-existent” g and a poor test of the supposedly real non-g abilities it was painstakingly designed to measure.\nThe triarchic theory of intelligence originated as an alternative to the concept of general intelligence factor, or g. (Vinney 2020; Brody 2003a, 2003b) analyzed Sternbergs work and finds a general factor of intelligence. Additionally, with tests that are radically different, Confirmatory Factor Analysis showed that different cognitive batteries (CAB, Hawaii Battery, WAIS) were analyzed, and it turned out that the g factors computed from the three tests (five tests in Johnson 2008) were statistically indistinguishable from one another, despite the fact that the tests tapped into partly different sets of abilities. (Johnson, 2004, 2008).\n\nOn a biological level, it has been established beyond any dispute that cognitive abilities are heritable. (Poldeman 2015) Higher g-loadings correlate to higher heritabilities (Rushton & Jensen 2010). Quantitative genetic analyses indicate that g is an even stronger genetic variable than it is a phenotypic variable. (Plomin & Spinath 2004)"
  },
  {
    "objectID": "7altmodels.html#is-mutualism-a-better-model-for-intelligence",
    "href": "7altmodels.html#is-mutualism-a-better-model-for-intelligence",
    "title": "7  Aren’t other models of intelligence more valid?",
    "section": "7.1 Is mutualism a better model for intelligence?",
    "text": "7.1 Is mutualism a better model for intelligence?\nMutualism, which states that “cognitive processes are initially uncorrelated, but that the positive manifold arises during individual development due to mutual beneficial relations between cognitive processes.”, has no good empirical backing. Mutualism expects that “it takes some time for the positive manifold, and thus the psychometric g factor, to emerge”, (Van Der Maas et al., 2006:851) but conversely, the proportion of variance in scale scores accounted for by a general factor is stable from age 2.5-90 (Gignac 2014) Thompson et al, (1985) even finds evidence for a genetic ‘g’ among infants. Mutualism would expect low genetic correlations among cognitive domains, however, more g-loaded tests are more heritable than the less g-loaded tests (and this exists in non humans as well). This is incredibly problematic. For example, in children, “correlations between phenotypic g loadings and genetic g loadings were 0.88 and 0.76 for the two mental test batteries.” (Deary et al., 2006) Additionally, “the effect of being raised in the same family is smaller than the effect of genes.” (Second Law of Behavioral Genetics) Mutualism fails to pass lex parsimoniae, is not generalisable, is not falsifiable, and is based mostly on post-hoc justifications. (Gignac 2016) Finally, under mutualism, we would expect changes to ‘g’ occurring after social changes and environmental impacts. However, IQ gains from adoption are not g-loaded, (Nijenhuis et al, 2015) IQ changes with education are not g-loaded (Nijenhuis et al, 2014; Ritchie et al 2015), etc BUT Gardner’s multiple theory of Intelligence is valid Gardner, the creator of the theory of multiple intelligences states that “I readily admit that the theory [of multiple intelligences] is no longer current. Several fields of knowledge have advanced significantly since the early 1980s. Any reinvigoration of the theory would require a survey similar to the one that colleagues and I carried out thirty-five years ago.” (Gardner, 2016, pp. 169–170). Hunt (2011:119), who stated that “there is virtually no objective evidence for the theory” of multiple intelligences. Gardner believes that those who espose general intelligence are “bad guys”. (Gardner, 2009, 0:45:11–0:45:32) Gardner seems to have called the abilities in his model, “intelligences” in order to “replace the current, [allegedly] largely discredited notion of intelligence as a single inherited trait” (Gardner, 2011:300).\nBy including physical abilities (in bodily-kinesthetic intelligence), personality traits (in interpersonal intelligence) and other non-cognitive traits, Gardner has stretched the word “intelligence” so much that it ceases to have any real meaning (Hunt, 2011; Jensen, 1998; Scarr, 1985). Gardner sees g as being a narrow concept that encourages “a limited view of intelligence” (von Károlyi et al., 2003), but believing in the existence of g does not preclude the existence of other abilities. In fact, both the currently accepted model of intelligence, the Cattell-Horn-Carroll model and bifactor models explicitly recognize the existence of non-g cognitive abilities\nIn order to make the theory of Multiple Intelligences, Gardner habitually cherry picks evidence in his favor and ignores evidence that contradicts his theory (Bouchard, 1984; Messick, 1992; Scarr, 1985; Snow, 1985). Frames of Mind also has the drawback of relying heavily on anecdotal data rather than any large, representative sample of individuals performing tasks grounded in his intelligences (Lubinski & Benbow, 1995).\nGardner’s theory is also unfalsifiable. Gardener states that he has “never felt that MI theory was one that could be subjected to an ‘up and down’ kind of test, or even series of tests” (Gardner, 2011, p. xix). And that he “[does] not believe that educational programs created under the aegis of MI theory lend themselves to the kinds of randomized control studies that the US government is now calling for in education” (Gardner, 2011:xxi). Gardner has stated that he does not endorse any psychological test to measure the multiple intelligences (von Károlyi et al., 2003)."
  },
  {
    "objectID": "7altmodels.html#isnt-emotional-intelligence-or-eq-more-powerful-than-iq",
    "href": "7altmodels.html#isnt-emotional-intelligence-or-eq-more-powerful-than-iq",
    "title": "7  Aren’t other models of intelligence more valid?",
    "section": "7.2 Isn’t Emotional Intelligence or EQ more powerful than IQ?",
    "text": "7.2 Isn’t Emotional Intelligence or EQ more powerful than IQ?\nEmotional Intelligence, “the capacity to reason, understand, and manage emotions. In addition, emotional intelligence plausibly reflects the emotion system’s capacity to use emotion to enhance thought”. Goleman describes it as “the ability to identify, monitor and accurately use information about emotional states” After Goleman’s 1996 book, “Emotional Intelligence”, the popular psychological term became a multi-million dollar industry. (Grewal and Salovey 2005) This fad (Murphy and Sideman 2006), like other fads in psychology, is unsubstantiated by the literature. Emotional Intelligence is not actually an independent construct, it seems to just measure various other factors that predict success. Joseph et al. (2015) reports that “62% of the variance in mixed EI is captured by Conscientiousness, Extraversion, Emotional Stability, ability EI, cognitive ability, general self-efficacy, and self-rated job performance.” which are all factors that predict success. This is also explored in Landy (2005).\nEmotional Intelligence’s construct validity is in question as some show it may merely be a repackaged version of the Big Five personality traits (Conte, 2005; van der Linden et al, 2017). Davies et al (2010) states “Our searches of the literature revealed only six articles in which the authors either explicitly examined the incremental validity of EI scores over measures of both cognitive ability and Big Five personality traits in predicting either academic or work performance, or presented data in a manner that allowed examination of this issue. Not one of these six articles… showed a significant contribution for EI in the prediction of performance after controlling for both cognitive ability and the Big Five… For correlations involving the overall EI construct, EI explained almost no incremental variance in performance ([change in prediction] = .00. Findings were identical when considering only cases involving an ability-based measure of IE….”. Harms and Crede (2010) states “…proofs of validity [for EI] seem to come from measuring constructs that have existed for a long time and are simply being relabeled and recategorized. For example, one of the proposed measures of ESC, the Trait Emotional Intelligence Questionnaire, makes use of measures of assertiveness, social competence, self-confidence, stress management, and impulsivity among other things. Most, if not all, of these constructs, are firmly embedded in and well-accounted for by [other] well-designed measures of personality traits… The substantial relationships observed between these ESC and trait-based EI measures, and personality inventories bear this out. It, therefore, appears that the predictive validity of ESC or EI measures may be accounted for in large part by the degree to which they assess sub-facets of higher-order traits relevant to the outcomes being predicted."
  },
  {
    "objectID": "7altmodels.html#is-iq-the-only-trait-that-predicts-outcomes",
    "href": "7altmodels.html#is-iq-the-only-trait-that-predicts-outcomes",
    "title": "7  Aren’t other models of intelligence more valid?",
    "section": "7.3 Is IQ the only trait that predicts outcomes?",
    "text": "7.3 Is IQ the only trait that predicts outcomes?\nAlthough intelligence is important in determining a student’s level of academic success, no one claims that intelligence is the only trait that impacts school outcomes. The correlation between IQ and measures of academic success – such as grades, standardized test scores, or how many years a person stays in school – is not perfect. That means that there is room for other abilities to exert an impact on educational performance. As Gottfredson (1997b, p. 116) stated, “The effects of intelligence … are probabilistic, not deterministic. Higher intelligence improves the odds of success in school and work. It is an advantage, not a guarantee. Many other things matter.” It is not difficult to brainstorm a list of what these “other things” that influence success are. Psychological traits like motivation, creativity, resiliency, curiosity, industriousness, and ambition can all be important for doing well in school. Non-psychological variables like socioeconomic status, parental involvement in education, a culture that encourages academic competition, and good physical health could also have an impact on a student’s success (Warne, 2016). Nobody denies this- but whether or not these variables\nThe argument among psychologists and educators is not whether non-cognitive variables can result in higher school performance. Rather, the argument is over the magnitude of the influence that these non-cognitive variables have and whether these variables are more important than intelligence in determining educational success. Personality traits have moderate importance in determining school performance, but they are hard to change. This resistance to interventions is probably because personality traits are – like almost every other psychological trait – partially influenced by genes. The heritability of personality is roughly the same as the heritability of intelligence, which may limit the malleability of personality (Bouchard, 1997, 2004; Briley & Tucker-Drob, 2017). Because of the difficulty of improving school performance by altering personality, many psychologists seek non-cognitive characteristics that are both malleable and important causes of academic achievement.\n\n7.3.1 Personality traits\nThe leading theory for personality, the Five Factor model, these traits are present in many cultures and across the lifespan, and they are a robust basis for understanding personality (Allik & Realo, 2017). Psychologists have conducted a great deal of research on the correlation between Big Five traits and school success. Although not perfectly consistent, this research shows that some of these traits correlate with educational outcomes. Conscientiousness has the strongest correlation, usually between r ≈ .20 and .35 (e.g., Cucina et al., 2016; Lechner et al, 2017; Poropat, 2009; Spinath et al, 2010). While this is a strong enough correlation for conscientiousness to be a noteworthy influence on school performance, it is weaker than the correlation between intelligence and academic performance, which is usually r ≈ .35 to .70 in the same studies. This indicates that intelligence is a more important influence on educational performance than conscientiousness is. The other personality traits in the Big Five have weaker relationships – in some studies as weak as zero – with academic achievement.\n\n\n7.3.2 Motivation\nThere is no denying the benefits of motivation. As one of the best non-cognitive influences on academics (Dalton, 2010; Liu et al, 2012), it is no surprise we see that motivated people set higher goals and accomplish more goals (Locke & Latham, 2002). Policies that encourage motivation in children result in greater dedication to their studies and higher performance in school (e.g., Patall et al, 2008; Roderick & Engel, 2001).\nMotivation, school performance, and IQ are all positively correlated with one another, and it is often difficult to disentangle their influences. In regards to intelligence, research shows that highly motivated examinees earn slightly higher IQ scores (Gignac et al, 2019). And because staying in school longer raises IQ (Ceci, 1991; Ritchie & Tucker Drob, 2018), it is possible that academically motivated students – who choose to stay in school longer – might earn higher IQs because of their additional education. However, none of this is evidence for whether increased motivation can cause higher g. Controlling for intelligence sometimes makes the relationship between motivation and academic performance disappear (e.g., Ziegler et al, 2010), though not always. And it is possible that motivation’s impact on IQ is entirely on the non-g influences on test scores. It does seem clear that improving student motivation can lead to gains in educational performance (Dalton, 2010). Motivation seems to have a stronger effect on grades than on standardized test scores (e.g., Cucina et al., 2016), possibly because earning high grades requires more sustained effort. Regardless, intelligence seems to be the more important predictor, no matter how academic performance is measured. As the authors of one study stated, “cognitive abilities were by far the best predictor of school achievement” (Gagné & St Père, 2001:71). Motivation – important as it is in determining academic outcomes – still is dwarfed by the influence of intelligence and other cognitive abilities. Therefore, no amount of motivation can make up for a large IQ deficit. (Warne, 2020)\n\n\n7.3.3 Mindset\nAccording to Dweck, there are two types of mindset: (a) fixed mindset and (b) growth mindset. (Dweck, 2009). There are several things that growth mindset are set out to achieve, most of which are minor or even associated with negative effects. Growth mindset is only slightly associated with goal setting. Bugonye et al, (2020) finds a correlation of 0.1 between having a growth mind-set and holding learning goals. For comparison, other personality constructs have been found to correlate much more strongly with learning goal orientation: self-efficacy (r = .56), need for achievement (r = .38), and openness to experience (r = .34); (Payne, Youngcourt, & Beaubien, 2007). Conversely, Burgoyne et al. (2020) finds no statistically significant associations between having a fixed-mindset and and performance goals. People with growth mindsets are not more intelligent. If anything, it is the opposite. Macnamara and Rupani (2017) find a insignificant correlation between mind-set and intelligence RMP (β = -0.04) Burgoyne et al, (2020) interestingly finds that mind-set has a very small negative correlation with cognitive ability tests. CFIT-4 (β = -0.10), Letter sets (β = -0.11), RPM (β = -0.12) People with growth mindset do not achieve more. Bahník and Vranka (2017) using university applicants who took an exam on scholastic aptitude (N = 5653) finds that growth mind-set was not positively associated with results of the test, did not predict change of the results for those who retook the test, did not predict participation in a future administration of the test, nor could it predict the total number of tests taken. Sisk et al, (2018), finds only a small correlation between mind-set and academic achievement (r = 0.1 and r=.08). Li and Bates (2020) find no association between growth mind-set and academic achievement. Growth mindset does not improve resilience- if anything, it is negatively associated with resilience. (Li and Bates 2019; Burgoyne et al, 2020)\n\n\n7.3.4 Grit\nGrit, formulated by Angela Duckworth, is perseverance and passion for long-term goals. (Duckworth et al, 2007:1087–1088) Grit seems to be extremely similar to the Big 5 trait, “conscientiousness”. The two traits correlate at = .66 to .84 (Credé et al, 2017). This correlation is so high that it indicates that there is little, if anything, new about grit at all. It is probably just a repackaged version of conscientiousness. (Warne 2020) A growing body of research studies shows that grit has no unique properties compared to more established non-cognitive variables (e.g., Dixson et al, 2016; Usher et al, 2019). Grit also does not seem like it can be grown. Rimfeld et al, (2016) finds that grit was substantially heritable, but found no evidence for a shared environmental influence on grit. Rimfeld et al. explained that “[t]he most limiting finding, for any possible intervention, is that shared environmental influence is negligible” (p. 786). Regardless, intelligence contributes 48-90 times more than grit and has a negligible effect on educational and economic success. (Zisman and Ganzach 2020) Credé et al, (2017) conducted a meta-analysis investigating the influence of grit and other traits on academic achievement, and found that while conscientiousness explained variance in academic achievement after controlling for grit, “overall grit explains no variance in either overall academic performance or high school GPA after controlling for conscientiousness” (p. 501)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alfonso, V. C., D. P. Flanagan, S. Radwan, D. P. Flanagan, and P. L.\nHarrison. 2005. “The Impact of the Cattell-Horn-Carroll Theory on\nTest Development and Interpretation of Cognitive and Academic\nAbilities.” In Contemporary Intellectual Assessment:\nTheories, Tests, and Issues, 185–202.\n\n\nBeal, A Lynne. 2006. “Review of Contemporary Intellectual\nAssessment, Theories, Tests and Issues.”\n\n\nBreslau, Joshua, Sergio Aguilar-Gaxiola, Kenneth S. Kendler, Maxwell Su,\nDavid Williams, and Ronald C. Kessler. 2006. “Specifying\nRace-Ethnic Differences in Risk for Psychiatric Disorder in a USA\nNational Sample.” Psychological Medicine 36 (1): 57–68.\nhttps://doi.org/10.1017/S0033291705006161.\n\n\nCanivez, G. L. 2017. “Test Review of Woodcock-Johnson® IV.”\nIn The Twentieth Mental Measurements Yearbook, edited by J. F.\nCarlson, K. F. Geisinger, and J. L. Jonson.\n\n\nCanivez, Gary, and Marley Watkins. 2016. “Review of the Wechsler\nIntelligence Scale for Children–Fifth Edition: Critique, Commentary, and\nIndependent Analyses.” In, 683–702.\n\n\nCarroll, J. B., C. J. B, and Cambridge University Press. 1993. Human\nCognitive Abilities: A Survey of Factor-Analytic Studies. Human\nCognitive Abilities: A Survey of Factor-Analytic Studies, no. 1.\nCambridge University Press. https://books.google.com/books?id=jp9dt4\\_0\\_cIC.\n\n\nCarroll, John. 2003. “The Higher-Stratum Structure of Cognitive\nAbilities: Current Evidence Supports g and about Ten Broad\nFactors.” In The Scientific Study of General Intelligence:\nTribute to Arthur R. Jensen, 5–21. https://doi.org/10.1016/B978-008043793-4/50036-2.\n\n\nClimie, Emma A., and Kristin Rostad. 2011. “Test Review: Wechsler\nAdult Intelligence Scale.” Journal of Psychoeducational\nAssessment 29 (6): 581–86. https://doi.org/10.1177/0734282911408707.\n\n\nColeman, Karen J., Christine Stewart, Beth E. Waitzfelder, John E.\nZeber, Leo S. Morales, Ameena T. Ahmed, Brian K. Ahmedani, et al. 2016.\n“Racial-Ethnic Differences in Psychiatric Diagnoses and Treatment\nAcross 11 Health Care Systems in the Mental Health Research\nNetwork.” Psychiatric Services 67 (7): 749–57. https://doi.org/10.1176/appi.ps.201500217.\n\n\nCormier, Damien C., Kathleen E. Kennedy, and Alexandra M. Aquilina.\n2016. “Test Review: Wechsler Intelligence Scale for Children,\nFifth Edition: Canadian 322 (WISC-VCDN) by d. Wechsler.”\nCanadian Journal of School Psychology 31 (4): 322–34. https://doi.org/10.1177/0829573516648941.\n\n\nCoyle, Thomas R. 2015. “Relations Among General Intelligence (g),\nAptitude Tests, and GPA: Linear Effects Dominate.”\nIntelligence 53: 16–22. https://doi.org/https://doi.org/10.1016/j.intell.2015.08.005.\n\n\nCurtin, Sally C, Kamiah A Brown, and Mariah E Jordan. 2022.\n“Suicide Rates for the Three Leading Methods by Race and Ethnicity\n: United States, 2000–2020.” NCHS Data Brief ; No. 450.\nhttps://dx.doi.org/10.15620/cdc:121798; National Center\nfor Health Statistics.\n\n\nDeary, I. J. 2000. Looking down on Human Intelligence: From\nPsychometrics to the Brain. Oxford Psychology Series. Oxford\nUniversity Press. https://books.google.com/books?id=GJcQAQAAIAAJ.\n\n\nDeary, Ian. 1998. “Differences in Mental Abilities.”\nBMJ (Clinical Research Ed.) 317 (7174): 1701–3. https://doi.org/10.1136/bmj.317.7174.1701.\n\n\n———. 2001. Intelligence: A Very Short Introduction. https://doi.org/10.1093/actrade/9780192893215.001.0001.\n\n\nDetterman, D K. 2000. “General Intelligence and the Definition of\nPhenotypes.” Novartis Foundation Symposium 233: 136-144;\ndiscussion 144-8. https://doi.org/10.1002/0470870850.ch9.\n\n\nDetterman, Douglas K. 2014. “You Should Be Teaching\nIntelligence!” Intelligence 42: 148–51.\nhttps://doi.org/https://doi.org/10.1016/j.intell.2013.07.021.\n\n\nFeldman, David Henry. 1984. “A Follow-up of Subjects Scoring Above\n180 IQ in Terman’s ‘Genetic Studies of Genius’.”\nExceptional Children 50 (6): 518–23. https://doi.org/10.1177/001440298405000604.\n\n\nFlanagan, Dawn P., and Shauna G. Dixon. 2014. “The\nCattell-Horn-Carroll Theory of Cognitive Abilities.” In\nEncyclopedia of Special Education. John Wiley & Sons, Ltd.\nhttps://doi.org/https://doi.org/10.1002/9781118660584.ese0431.\n\n\nFlore, Paulette C., and Jelte M. Wicherts. 2015. “Does Stereotype\nThreat Influence Performance of Girls in Stereotyped Domains? A\nMeta-Analysis.” Journal of School Psychology 53 (1):\n25–44. https://doi.org/https://doi.org/10.1016/j.jsp.2014.10.002.\n\n\nFlores, AJ, TA Chavez, N Bolger, and BJ Casad. 2021. “Retraction\nNotice.” Personality and Social Psychology Bulletin 47\n(1): 161–61. https://doi.org/10.1177/0146167220973962.\n\n\nGladwell, M. 2008. Outliers: The Story of Success. Penguin\nBooks Limited. https://books.google.com/books?id=ialrgIT41OAC.\n\n\nGoodenough, FL. 1926. “Racial Differences in the Intelligence of\nSchool Children.” Journal of Experimental Psychology 9\n(4): 388–97. https://doi.org/10.1037/h0073325.\n\n\nGottfredson, Linda S. 1997. “Mainstream Science on Intelligence:\nAn Editorial with 52 Signatories, History, and Bibliography.”\nIntelligence 24 (1): 13–23. https://doi.org/https://doi.org/10.1016/S0160-2896(97)90011-8.\n\n\n———. 2002. “G: Highly General and Highly Practical.” In\nThe General Factor of Intelligence: How General Is It?, 331–80.\nMahwah, NJ, US: Lawrence Erlbaum Associates Publishers. https://doi.org/10.4324/9781410613165.\n\n\nGuldemond, Henk, Roel Bosker, Hans Kuyper, and Greetje van der Werf.\n2007. “Do Highly Gifted Students Really Have Problems?”\nEducational Research and Evaluation 13 (6): 555–68. https://doi.org/10.1080/13803610701786038.\n\n\nGustafsson, Jan-Eric. 1984. “A Unifying Model for the Structure of\nIntellectual Abilities.” Intelligence 8 (3): 179–203.\nhttps://doi.org/https://doi.org/10.1016/0160-2896(84)90008-4.\n\n\nHaier, Richard J. 2019. “Alive and Well,\nIntelligence Research on the Move.” The American\nJournal of Psychology 132 (2): 259–62. https://doi.org/10.5406/amerjpsyc.132.2.0259.\n\n\nHaworth, C. M. A., M. J. Wright, M. Luciano, N. G. Martin, E. J. C. de\nGeus, C. E. M. van Beijsterveldt, M. Bartels, et al. 2010. “The\nHeritability of General Cognitive Ability Increases Linearly from\nChildhood to Young Adulthood.” Molecular Psychiatry 15\n(11): 1112–20. https://doi.org/10.1038/mp.2009.55.\n\n\nHill, W. D., R. E. Marioni, O. Maghzian, S. J. Ritchie, S. P. Hagenaars,\nA. M. McIntosh, C. R. Gale, G. Davies, and I. J. Deary. 2019. “A\nCombined Analysis of Genetically Correlated Traits Identifies 187 Loci\nand a Role for Neurogenesis and Myelination in Intelligence.”\nMolecular Psychiatry 24 (2): 169–81. https://doi.org/10.1038/s41380-017-0001-5.\n\n\nHunter, John E, and Frank L Schmidt. 2000. “Racial and Gender Bias\nin Ability and Achievement Tests: Resolving the Apparent\nParadox.” Psychology, Public Policy, and Law 6 (1):\n151–58. https://doi.org/10.1037/1076-8971.6.1.151.\n\n\nJanzen, Henry L., John E. Obrzut, and Christopher W. Marusiak. 2004.\n“Test Review: Roid, g. H. (2003). Stanford-Binet Intelligence\nScales, Fifth Edition (SB:v). Itasca, IL: Riverside Publishing.”\nCanadian Journal of School Psychology 19 (1-2): 235–44. https://doi.org/10.1177/082957350401900113.\n\n\nJensen, A. R. 1980. Bias in Mental Testing. Free Press. https://books.google.com/books?id=wJR9AAAAMAAJ.\n\n\nJensen, Arthur R., and Frank C. J. McGurk. 1987. “Black-White Bias\nin ‘Cultural’ and ‘Noncultural’ Test\nItems.” Personality and Individual Differences 8 (3):\n295–301. https://doi.org/https://doi.org/10.1016/0191-8869(87)90029-8.\n\n\nJewsbury, Paul, Stephen Bowden, and Kevin Duff. 2017. “The\nCattell–Horn–Carroll Model of Cognition for Clinical Assessment.”\nJournal of Psychoeducational Assessment 35 (6): 547–67. https://doi.org/10.1177/0734282916651360.\n\n\nJohnson, Wendy, Thomas J Bouchard, Robert F Krueger, Matt McGue, and\nIrving I Gottesman. 2004. “Just One g: Consistent Results from\nThree Test Batteries.” Intelligence 32 (1): 95–107.\nhttps://doi.org/https://doi.org/10.1016/S0160-2896(03)00062-X.\n\n\nJohnson, Wendy, Jan te Nijenhuis, and Thomas J. Bouchard. 2008.\n“Still Just 1 g: Consistent Results from Five Test\nBatteries.” Intelligence 36 (1): 81–95.\nhttps://doi.org/https://doi.org/10.1016/j.intell.2007.06.001.\n\n\nKeith, Timothy, John Kranzler, and Dawn Flanagan. 2001. “What Does\nthe Cognitive Assessment System (CAS) Measure? Joint Confirmatory Factor\nAnalysis of the CAS and the Woodcock-Johnson Tests of Cognitive\nAbility.” School Psychology Review 30 (March): 89–119.\nhttps://doi.org/10.1080/02796015.2001.12086102.\n\n\nKell, Harrison J., David Lubinski, and Camilla P. Benbow. 2013.\n“Who Rises to the Top? Early Indicators.” Psychological\nScience 24 (5): 648–59. https://doi.org/10.1177/0956797612457784.\n\n\nKendler, Kenneth S., Eric Turkheimer, Henrik Ohlsson, and Kristina\nSundquist. 2015. “Family Environment and the Malleability of\nCognitive Ability: A Swedish National Home-Reared and Adopted-Away\nCosibling Control Study.” Edited by Richard E. Nisbett.\nProceedings of the National Academy of Sciences 112 (15):\n4612–17. https://doi.org/10.1073/pnas.1417106112.\n\n\nKrueger, Patrick M, Jarron M Saint Onge, and Virginia W Chang. 2011.\n“Race/Ethnic Differences in Adult Mortality: The Role of Perceived\nStress and Health Behaviors.” Social Science &\nMedicine 73 (9): 1312–22. https://doi.org/10.1016/j.socscimed.2011.08.007.\n\n\nLubinski, David. 2004. “Introduction to the Special Section on\nCognitive Abilities: 100 Years After Spearman’s (1904) \"’General\nIntelligence,’ Objectively Determined and Measured\".” Journal\nof Personality and Social Psychology 86 (1): 96–111. https://doi.org/10.1037/0022-3514.86.1.96.\n\n\n———. 2009a. “Cognitive Epidemiology: With Emphasis on Untangling\nCognitive Ability and Socioeconomic Status.”\nIntelligence 37: 625–33. https://doi.org/10.1016/j.intell.2009.09.001.\n\n\n———. 2009b. “Exceptional Cognitive Ability: The Phenotype.”\nBehavior Genetics 39: 350–58. https://doi.org/10.1007/s10519-009-9273-0.\n\n\nMackintosh, Nicholas. 2011. IQ and Human Intelligence. OUP\nOxford. https://books.google.com/books?id=BcKcAQAAQBAJ.\n\n\nMadle, R. A. 2017. “[Test Review of Woodcock-Johnson® IV].”\nIn The Twentieth Mental Measurements Yearbook, edited by J. F.\nCarlson, K. F. Geisinger, and J. L. Jonson.\n\n\nMakel, Matthew C., Harrison J. Kell, David Lubinski, Martha Putallaz,\nand Camilla P. Benbow. 2016. “When Lightning Strikes Twice:\nProfoundly Gifted, Profoundly Accomplished.” Psychological\nScience 27 (7): 1004–18. https://doi.org/10.1177/0956797616644735.\n\n\nMcGrew, Kevin S, DP Flanagan, JL Genshaft, and PL Harrison. 2005.\nContemporary Intellectual Assessment: Theories, Tests, and\nIssues. The Guilford Press New York, NY, USA:\n\n\nMcGue, Matt, Margaret Keyes, Anu Sharma, Irene Elkins, Lisa Legrand,\nWendy Johnson, and William G. Iacono. 2007. “The Environments of\nAdopted and Non-Adopted Youth: Evidence on Range Restriction from the\nSibling Interaction and Behavior Study (SIBS).” Behavior\nGenetics 37 (3): 449–62. https://doi.org/10.1007/s10519-007-9142-7.\n\n\nMurray, C. A. 1998. Income Inequality and IQ. AEI Studies on\nUnderstanding e. AEI Press. https://books.google.com/books?id=rrdNL4dpijwC.\n\n\nNeisser, Ulric, Gwyneth Boodoo, Thomas J. Bouchard Jr., A. Wade Boykin,\nNathan Brody, Stephen J. Ceci, Diane F. Halpern, et al. 1996.\n“Intelligence: Knowns and Unknowns.” American\nPsychologist 51 (2): 77–101. https://doi.org/10.1037/0003-066X.51.2.77.\n\n\nOpen Science Collaboration. 2015. “Estimating the Reproducibility\nof Psychological Science.” Science 349 (6251): aac4716.\nhttps://doi.org/10.1126/science.aac4716.\n\n\nPlomin, R, and I J Deary. 2015. “Genetics and Intelligence\nDifferences: Five Special Findings.” Molecular\nPsychiatry 20 (1): 98–108. https://doi.org/10.1038/mp.2014.105.\n\n\nPorteus, SD. 1965. Porteus Maze Test; Fifty Years’ Application.\nPacific Books.\n\n\nReeve, Charlie L., and Jennifer E. Charles. 2008. “Survey of\nOpinions on the Primacy of g and Social Consequences of Ability Testing:\nA Comparison of Expert and Non-Expert Views.”\nIntelligence 36 (6): 681–88. https://doi.org/https://doi.org/10.1016/j.intell.2008.03.007.\n\n\nReynolds, Cecil R. 2000. “Why Is Psychometric Research on Bias in\nMental Testing so Often Ignored?” Psychology, Public Policy,\nand Law 6 (1): 144–50. https://doi.org/10.1037/1076-8971.6.1.144.\n\n\nReynolds, Cecil R. 1995. “Test Bias and the Assessment of\nIntelligence and Personality.” In International Handbook of\nPersonality and Intelligence, edited by Donald H. Saklofske and\nMoshe Zeidner, 545–73. Boston, MA: Springer US. https://doi.org/10.1007/978-1-4757-5571-8_25.\n\n\n———. 1998. “10.03 - Cultural Bias in Testing of Intelligence and\nPersonality.” In Comprehensive Clinical Psychology,\nedited by Alan S. Bellack and Michel Hersen, 53–92. Oxford: Pergamon.\nhttps://doi.org/https://doi.org/10.1016/B0080-4270(73)00105-X.\n\n\nReynolds, Cecil R., and Robert T. Brown. 1984. “Bias in Mental\nTesting.” In Perspectives on Bias in Mental Testing,\nedited by Cecil R. Reynolds and Robert T. Brown, 1–39. Boston, MA:\nSpringer US. https://doi.org/10.1007/978-1-4684-4658-6_1.\n\n\nReynolds, Cecil R., and Lisa A. Suzuki. 2012. “Bias in\nPsychological Assessment.” In Handbook of Psychology, Second\nEdition. John Wiley & Sons, Ltd. https://doi.org/https://doi.org/10.1002/9781118133880.hop210004.\n\n\nRindermann, Heiner, David Becker, and Thomas R. Coyle. 2020.\n“Survey of Expert Opinion on Intelligence: Intelligence Research,\nExperts’ Background, Controversial Issues, and the Media.”\nIntelligence 78: 101406. https://doi.org/https://doi.org/10.1016/j.intell.2019.101406.\n\n\nRiolo, Stephanie A., Tuan Anh Nguyen, John F. Greden, and Cheryl A.\nKing. 2005. “Prevalence of Depression by Race/Ethnicity: Findings\nfrom the National Health and Nutrition Examination Survey III.”\nAmerican Journal of Public Health 95 (6): 998–1000. https://doi.org/10.2105/AJPH.2004.047225.\n\n\nRuf, D. L. 2005. Losing Our Minds: Gifted Children Left Behind.\nGreat Potential Press. https://books.google.com/books?id=RnWY5TCJr1QC.\n\n\nRutter, Michael. 2000. “Closing Remarks.” In The Nature\nof Intelligence, 281–87. John Wiley & Sons, Ltd.\nhttps://doi.org/https://doi.org/10.1002/0470870850.ch18.\n\n\nSavage, Jeanne E., Philip R. Jansen, Sven Stringer, Kyoko Watanabe,\nJulien Bryois, Christiaan A. de Leeuw, Mats Nagel, et al. 2018.\n“Genome-Wide Association Meta-Analysis in 269,867 Individuals\nIdentifies New Genetic and Functional Links to Intelligence.”\nNature Genetics 50 (7): 912–19. https://doi.org/10.1038/s41588-018-0152-6.\n\n\nSchimmack, Ulrich. 2017. “Hidden Figures: Replication Failures in\nthe Stereotype Threat Literature.” https://replicationindex.com/2017/04/07/hidden-figures-replication-failures-in-the-stereotype-threat-literature/.\n\n\nSchneider, W Joel, Kevin S McGrew, DP Flanagan, and PL Harrison. 2012.\n“Contemporary Intellectual Assessment: Theories, Tests, and\nIssues.” Institute for Applied Psychometrics (IAP).\n\n\nShewach, Oren R, Paul R Sackett, and Sander Quint. 2019.\n“Stereotype Threat Effects in Settings with Features Likely Versus\nUnlikely in Operational Test Settings: A Meta-Analysis.”\nJournal of Applied Psychology 104 (12): 1514–34. https://doi.org/10.1037/apl0000420.\n\n\nSirin, Selcuk R. 2005. “Socioeconomic Status and Academic\nAchievement: A Meta-Analytic Review of Research.” Review of\nEducational Research 75: 417–53. https://doi.org/10.3102/00346543075003417.\n\n\nSniekers, Suzanne, Sven Stringer, Kyoko Watanabe, Philip R. Jansen,\nJonathan R. I. Coleman, Eva Krapohl, Erdogan Taskesen, et al. 2017.\n“Genome-Wide Association Meta-Analysis of 78,308 Individuals\nIdentifies New Loci and Genes Influencing Human Intelligence.”\nNature Genetics 49 (7): 1107–12. https://doi.org/10.1038/ng.3869.\n\n\nSnyderman, Mark, and Stanley Rothman. 1987. “Survey of Expert\nOpinion on Intelligence and Aptitude Testing.” American\nPsychologist 42: 137–44. https://doi.org/10.1037/0003-066X.42.2.137.\n\n\nStauffer, Joseph M., Malcolm James Ree, and Thomas R. Carretta. 1996.\n“Cognitive-Components Tests Are Not Much More Than g: An Extension\nof Kyllonen’s Analyses.” The Journal of General\nPsychology 123 (3): 193–205. https://doi.org/10.1080/00221309.1996.9921272.\n\n\nSternberg, Robert J. 2003. “Chapter 17 - ‘My House Is a Very\nVery Very Fine House’ —but It Is Not the Only House.” In\nThe Scientific Study of General Intelligence, edited by Helmuth\nNyborg, 373–95. Oxford: Pergamon. https://doi.org/https://doi.org/10.1016/B978-008043793-4/50056-8.\n\n\nStrenze, Tarmo. 2007. “Intelligence and Socioeconomic Success: A\nMeta-Analytic Review of Longitudinal Research.”\nIntelligence 35 (5): 401–26. https://doi.org/https://doi.org/10.1016/j.intell.2006.09.004.\n\n\nte Nijenhuis, Jan, Birthe Jongeneel-Grimen, and Elijah L. Armstrong.\n2015. “Are Adoption Gains on the g Factor? A\nMeta-Analysis.” Personality and Individual Differences\n73: 56–60. https://doi.org/https://doi.org/10.1016/j.paid.2014.09.022.\n\n\nTwenge, Jean M, and Jennifer Crocker. 2002. “Race and Self-Esteem:\nMeta-Analyses Comparing Whites, Blacks, Hispanics, Asians, and American\nIndians and Comment on Gray-Little and Hafdahl (2000).”\nPsychological Bulletin 128 (3): 371–408. https://doi.org/10.1037/0033-2909.128.3.371.\n\n\nVan der Maas, Han L. J., Kees-Jan Kan, and Denny Borsboom. 2014.\n“Intelligence Is What the Intelligence Test Measures.\nSeriously.” Journal of Intelligence 2 (1): 12–15. https://doi.org/10.3390/jintelligence2010012.\n\n\nWai, Jonathan. 2014. “Experts Are Born, Then Made: Combining\nProspective and Retrospective Longitudinal Data Shows That Cognitive\nAbility Matters.” Intelligence 45: 74–80.\nhttps://doi.org/https://doi.org/10.1016/j.intell.2013.08.009.\n\n\nWakeford, Richard, Kasia Ludka, Katherine Woolf, and I. C. McManus.\n2018. “Fitness to Practise Sanctions in UK Doctors Are Predicted\nby Poor Performance at MRCGP and MRCP(UK) Assessments: Data Linkage\nStudy.” BMC Medicine 16: 230. https://doi.org/10.1186/s12916-018-1214-4.\n\n\nWalker, Nicholas P, Pauline M McConville, David Hunter, Ian J Deary, and\nLawrence J Whalley. 2002. “Childhood Mental Ability and Lifetime\nPsychiatric Contact: A 66-Year Follow-up Study of the 1932 Scottish\nMental Ability Survey.” Intelligence 30 (3): 233–45.\nhttps://doi.org/https://doi.org/10.1016/S0160-2896(01)00098-8.\n\n\nWarne, R. T. 2020. In the Know: Debunking 35 Myths about Human\nIntelligence. Cambridge University Press. https://books.google.com/books?id=TtX7DwAAQBAJ.\n\n\nWigdor, Alexandra K. 1982. “Ability Testing: Uses, Consequences,\nand Controversies.” Educational Measurement: Issues and\nPractice 1 (3): 6–8. https://doi.org/https://doi.org/10.1111/j.1745-3992.1982.tb00659.x.\n\n\nWilliams, Camille Michèle, Hugo Peyre, Ghislaine Labouret, Judicael\nFassaya, Adoración Guzmán Garcı́a, Nicolas Gauvrit, and Franck Ramus.\n2022. “High Intelligence Is Not a Risk Factor for Mental Health\nDisorders.” medRxiv. https://doi.org/10.1101/2022.05.26.22275621."
  },
  {
    "objectID": "7altmodels.html#dont-we-have-multiple-intelligences",
    "href": "7altmodels.html#dont-we-have-multiple-intelligences",
    "title": "7  Aren’t other models of intelligence more valid?",
    "section": "7.1 Don’t we have multiple intelligences?",
    "text": "7.1 Don’t we have multiple intelligences?\nGardner, the creator of the theory of multiple intelligences states that “I readily admit that the theory [of multiple intelligences] is no longer current. Several fields of knowledge have advanced significantly since the early 1980s. Any reinvigoration of the theory would require a survey similar to the one that colleagues and I carried out thirty-five years ago.” (Gardner, 2016, pp. 169–170). Hunt (2011:119), who stated that “there is virtually no objective evidence for the theory” of multiple intelligences. Gardner believes that those who espose general intelligence are “bad guys”. (Gardner, 2009, 0:45:11–0:45:32) Gardner seems to have called the abilities in his model, “intelligences” in order to “replace the current, [allegedly] largely discredited notion of intelligence as a single inherited trait” (Gardner, 2011:300).\nBy including physical abilities (in bodily-kinesthetic intelligence), personality traits (in interpersonal intelligence) and other non-cognitive traits, Gardner has stretched the word “intelligence” so much that it ceases to have any real meaning (Hunt, 2011; Jensen, 1998; Scarr, 1985). Gardner sees g as being a narrow concept that encourages “a limited view of intelligence” (von Károlyi et al., 2003), but believing in the existence of g does not preclude the existence of other abilities. In fact, both the currently accepted model of intelligence, the Cattell-Horn-Carroll model and bifactor models explicitly recognize the existence of non-g cognitive abilities\nIn order to make the theory of Multiple Intelligences, Gardner habitually cherry picks evidence in his favor and ignores evidence that contradicts his theory (Bouchard, 1984; Messick, 1992; Scarr, 1985; Snow, 1985). Frames of Mind also has the drawback of relying heavily on anecdotal data rather than any large, representative sample of individuals performing tasks grounded in his intelligences (Lubinski & Benbow, 1995).\nGardner’s theory is also unfalsifiable. Gardener states that he has “never felt that MI theory was one that could be subjected to an ‘up and down’ kind of test, or even series of tests” (Gardner, 2011, p. xix). And that he “[does] not believe that educational programs created under the aegis of MI theory lend themselves to the kinds of randomized control studies that the US government is now calling for in education” (Gardner, 2011:xxi). Gardner has stated that he does not endorse any psychological test to measure the multiple intelligences (von Károlyi et al., 2003)."
  },
  {
    "objectID": "7altmodels.html#what-about-mutualism",
    "href": "7altmodels.html#what-about-mutualism",
    "title": "7  Aren’t other models of intelligence more valid?",
    "section": "7.4 What about mutualism?",
    "text": "7.4 What about mutualism?\nMutualism, which states that “cognitive processes are initially uncorrelated, but that the positive manifold arises during individual development due to mutual beneficial relations between cognitive processes.”, has no good empirical backing. Mutualism expects that “it takes some time for the positive manifold, and thus the psychometric g factor, to emerge”, (Van Der Maas et al., 2006:851) but conversely, the proportion of variance in scale scores accounted for by a general factor is stable from age 2.5-90 (Gignac 2014) Thompson et al, (1985) even finds evidence for a genetic ‘g’ among infants. Mutualism would expect low genetic correlations among cognitive domains, however, more g-loaded tests are more heritable than the less g-loaded tests (and this exists in non humans as well). This is incredibly problematic. For example, in children, “correlations between phenotypic g loadings and genetic g loadings were 0.88 and 0.76 for the two mental test batteries.” (Deary et al., 2006) Additionally, “the effect of being raised in the same family is smaller than the effect of genes.” (Second Law of Behavioral Genetics) Mutualism fails to pass lex parsimoniae, is not generalisable, is not falsifiable, and is based mostly on post-hoc justifications. (Gignac 2016) Finally, under mutualism, we would expect changes to ‘g’ occurring after social changes and environmental impacts. However, IQ gains from adoption are not g-loaded, (Nijenhuis et al, 2015) IQ changes with education are not g-loaded (Nijenhuis et al, 2014; Ritchie et al 2015), etc"
  }
]