{"title":"What do intelligence tests measure?","markdown":{"headingText":"What do intelligence tests measure?","containsRefs":false,"markdown":"\nIntelligence tests aim to measure an individual's general cognitive ability, commonly referred to as the g factor. Research has consistently shown that virtually every cognitive battery is highly g-loaded, meaning that the tasks on these tests share a common factor of general intelligence. In other words, individuals who perform well on one cognitive task are likely to perform well on other cognitive tasks, indicating a positive correlation between various cognitive abilities. \n\nThe high g-loading of intelligence tests indicates that these tests are measuring a broad and general factor of intelligence that is common to all cognitive tasks. The g factor is not limited to specific abilities, such as memory or verbal fluency, but rather represents a general cognitive ability that influences performance across a range of tasks. Therefore, it is reasonable to argue that intelligence tests measure intelligence, specifically, the g factor.\n\nWhile intelligence tests may not perfectly measure intelligence and may not capture 100 percent of the variance of cognitive ability, empirical evidence supports their validity and reliability as measures of general intelligence. [@vandermaas2014]\n\n## The Positive Manifold \nThe positive manifold refers to the observation that all intelligence subtests, including scholastic and social intelligence tests, correlate positively. This pattern indicates that intelligence can be measured as a composite score derived from various cognitive abilities. \n\nThe consistency of this positive correlation, known as the g factor, has been observed even in tests initially designed to measure other traits or abilities. Since it is so easy for cognitive batteries to measure intelligence, some tests that were created with the intention of measuring more narrow abilities end up unintentionally measuring the g-factor. For example, the Cognitive Assessment System (CAS) and the Cognitive Abilities Measurement (CAM) battery were both designed to measure cognitive processes – not g, but they still measure g anyway [@keith2001]; [@stauffer1996]. Confirmatory factor analysis showed that different cognitive batteries (CAB, Hawaii Battery, WAIS) were analyzed, and it turned out that the g factors computed from the three tests (five tests in Johnson 2008) were statistically indistinguishable from one another, despite the fact that the tests tapped into partly different sets of abilities [@johnson2004]; [@johnson2008]. \n\n## Are intelligence tests reliable?\n\nIntelligence tests are among the most reliable and valid psychological tests and assessments and as such, they are used extensively in educational, organizational, and clinical settings [@detterman2014]. \n\nAccording to the Wikipedia page on IQ:\n\n_The most commonly used individual IQ test series is the Wechsler Adult Intelligence Scale (WAIS) for adults and the Wechsler Intelligence Scale for Children (WISC) for school-age test-takers. Other commonly used individual IQ tests (some of which do not label their standard scores as \"IQ\" scores) include the current versions of the Stanford–Binet Intelligence Scales, Woodcock–Johnson Tests of Cognitive Abilities..._\n\nFor brevity, I will only focus on the first four tests mentioned: WAIS, WISC, SB5, and WJ-IV.\n\n### Wechsler Adult Intelligence Scale (WAIS)\n\nAccording to a review by @climie2011\n\n- Internal consistency. The WAIS-IV's reliability was measured using split-half and Cronbach's coefficient alpha. All reported values were based on U.S. norms. The average reliability coefficients for the subtest scores ranged from acceptable (.78) to excellent (≥.90), while the four composite scores had excellent reliability coefficients (all ≥.90), with the FSIQ reporting a reliability coefficient of .98.\n- Test-retest reliability. Test-retest reliabilities were obtained using Pearson's product-moment correlation for four age bands (16-29, 30-54, 55-69, and 70-90), with time intervals between testing ranging from 8 to 82 days and a mean of 22 days. Overall, the WAIS-IV has acceptable stability across time for each of the four age bands. Subtest stability coefficients range from adequate (.74) to excellent (.90), with a majority of scores falling within the good range (.80s). Composite scores ranged from .87 to .96, with the FSIQ stability coefficient reaching an excellent value of .96.\n- Interrater reliability. To ascertain acceptable levels of interrater reliability, all WAIS-IV protocols were scored by two independent scorers. General interrater agreement was high (.98 to .99), and for the verbal subtests, raters obtained excellent levels of reliability, ranging from .91 to .97.\n\n\n### Wechsler Intelligence Scale for Children (WISC)\n\nAccording to a review by @cormier2016\n\n- The formula used to calculate internal consistency reliability was recommended by Guilford (1954), Haertel (2006), and Nunnally and Bernstein (1994).\n- Fisher's z transformation was used to calculate the average reliability coefficients.\n- Internal consistency reliability for composite, subtest, and process scores ranges from r = .80 to r = .96.\n- The split-half method was used to calculate the reliability coefficients for all subtests, except for Coding, Symbol Search, Cancellation, Naming Speed Literacy, Naming Speed Quantity, Immediate Symbol Translation, or Delayed Symbol Translation subtests.\n- The average reliability coefficient for FSIQ is r = .96.\n- The average reliability coefficients for the primary and secondary subtests range from r = .81 to r = .94.\n- The process scores reliability coefficients range from r = .80 to r = .85.\n- The overall reliability coefficients for the primary index scores range from r = .88 to r = .93, and for the ancillary index scores range from r = .92 to r = .95.\n- Test-retest reliability coefficients ranged from r = .71 to r = .94, with a mean test-retest interval of 26 days.\n- Evidence of inter-scorer agreement was obtained, with the range of inter-scorer agreement being r = .98 to r = .99.\n- The average of the reliability coefficients for primary and secondary subtests from the WISC-VCDN ranges from good to excellent.\n- The reliability estimates for the WISC-VCDN scores demonstrate strong precision, which contributes to minimizing the effects of error in the measurement of the targeted abilities.\n\n\nAccording to a review by @canivez2016\n\n- Reliability estimates of WISC-V scores reported in the WISC-V Technical and Interpretive Manual were derived using three methods: internal consistency, test-retest (stability), and interscorer agreement. \n- Internal consistency was measured through the use of split-half and Cronbach’s coefficient alpha, with data provided for each of the 15 core and supplemental subtests and five composite scores (including the FSIQ). \n- Test-retest reliabilities were obtained through repeated administration of the WAIS-IV, with time intervals between testing ranging from 8 to 82 days and a mean of 22 days. \n- To ascertain acceptable levels of interrater reliability, all WAIS-IV protocols were scored by two independent scorers. \n- Average coefficients across the 11 age groups for the composite scores ranged from .88 to .96 and were higher than those obtained for subtests and process scores. \n- Internal consistency estimates for the primary and secondary subtests ranged from .81 to .94 while process scores ranged from .80 to .88. \n- Reliability estimates for the complementary subtests, process, and composite scores are provided. \n- Standard errors of measurement based on reliability coefficients are presented in Table 4.4 of the WISC-V Technical and Interpretive Manual. \n- Short-term test-retest stability estimates were provided for WISC-V scores where the WISC-V was twice administered to a sample of 218 children. \n- Interscorer agreement ranged from .97 to .99. \n\n### Stanford–Binet Intelligence Scales, Fifth Edition (SB-V)\n\nAccording to a review by @janzen2004\n\n- The internal consistency (split-half reliability) for the Full Scale IQ (FSIQ), Nonverbal IQ (NVIQ), and Verbal IQ (VIQ) ranges between .95 and .98; for the five Factor Indices, it is between .90 and .92; and, for the ten subtests, it ranges between .84 and .89.\n- IQ scores on the SB:V appear to be quite stable across time and less affected by practice effects.\n- The median inter-scorer correlation is .90, and correlations on multiple-point responses (0, 1, 2) range from .74 to .97.\n\n\n### Woodcock–Johnson Tests of Cognitive Abilities\n\nAccording to a review by @canivez2017\n\n- Internal consistency reliabilities for untimed tests and dichotomously scored items were estimated with the split-half method, whereas tests with subtests and cluster reliabilities were estimated with Mosier's (1943) formula for unweighted composites.\n- Reliability for speeded tests was estimated using the test-retest method with a 1-day retest interval, and correlations were corrected for range restriction.\n- Median reliability coefficients were uniformly high: 38 of 39 were .80 or higher, and 17 were .90 or higher. Test-retest correlations for speeded tests were mostly in the .80 to .90 range.\n- Cluster scores include two or more tests and as such produce higher reliability estimates as predicted by true score theory. The WJ IV technical manual recommended using cluster scores in interpretation, especially when used in individual decision-making.\n- Model-based reliability coefficients (omega hierarchical) could be assessed to determine unique true score variance captured by the different scores.\n- Alternate forms equivalence was examined and item difficulty and content were found to be similar among the forms.\n\nAccording to @madle2017\n\n- Median internal consistency coefficient for WJ IV COG GIA score is .97, with median coefficients of .95 to .97 for different age groups\n- Gf-Gc reliability coefficients range from .94 to .98 (median = .96)\n- BIA reliability coefficient median is .94 (.92-.95)\n- Median coefficients for the various cognitive clusters range from .86 (Visual Processing) to .91 (Short-Term Working Memory)\n- Oral Language reliability coefficients range from .89 for Oral Expression to .92 for Broad Oral Language\n- Academic cluster median reliability coefficients range from .92 to .97, with a Broad Achievement score median reliability coefficient of .99\n- Test-retest studies were completed for speeded tests only, and median reliability coefficients ranged from .88 to .92 for three different age groups\n- Equivalence of item difficulties and item content for the achievement forms was examined and found to be strong.\n\n## Are intelligence tests statistically valid?\n\n__To be added: test validity- too much to add rn__\n\n### Wechsler Adult Intelligence Scale (WAIS)\n\n### Wechsler Intelligence Scale for Children (WISC)\n\n### Stanford–Binet Intelligence Scales, Fifth Edition (SB-V)\n\n### Woodcock–Johnson Tests of Cognitive Abilities\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"2justtests.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.280","bibliography":["references.bib"],"theme":"pulse"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"2justtests.pdf"},"language":{},"metadata":{"block-headings":true,"bibliography":["references.bib"],"documentclass":"scrreprt"},"extensions":{"book":{}}}}}